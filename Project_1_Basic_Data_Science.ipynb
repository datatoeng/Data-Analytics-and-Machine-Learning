{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Lab_1.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"TBvzhAlwoJFp","colab_type":"text"},"source":["# APS1070\n","#### Basic Principles and Models - Project 1\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hJqa8JCbsXAR","colab_type":"text"},"source":["Project 1 has two parts: a tutorial component (which will be covered in labs) and an exercises component (to be completed as homework, individually). Overall, this project is worth 12.5% of your final grade. Completing the tutorial section is worth 2.5 marks. The exercises section will be graded out of the remaining 10 marks."]},{"cell_type":"markdown","metadata":{"id":"AC7fb3NUoJFq","colab_type":"text"},"source":["In this first lab, we will be using the popular machine learning library [scikit-learn](https://scikit-learn.org/stable/) in tandem with a popular scientific computing library in Python, [NumPy](https://www.numpy.org/), to investigate basic machine learning principles and models. The topics that will be covered in this lab include:\n","* Introduction to scikit-learn and NumPy\n","* Data preparation and cleaning with Pandas\n","* Exploratory data analysis (EDA)\n","* Nearest neighbors classification algorithm\n","\n","*Note:* Some other useful Python libraries include [matplotlib](https://matplotlib.org/) (for plotting/graphing) and [Pandas](https://pandas.pydata.org/) (for data analysis), though we won't be going into detail on these in this bootcamp. \n","\n","##### Jupyter Notebooks\n","This lab will be using [Jupyter Notebooks](https://jupyter.org/) as a Python development environment. Hopefully you're somewhat familiar with them. Write your code in *cells* (this is a cell!) and execute your code by pressing the *play* button (up top) or by entering *ctrl+enter*. To format a cell for text, you can select \"Markdown\" from the dropdown - the default formatting is \"Code\", which will usually be what you want.\n","\n","#### Getting started\n","Let's get started. First, we're going to test that we're able to import the required libraries.  \n","**>> Run the code in the next cell** to import scikit-learn and NumPy."]},{"cell_type":"code","metadata":{"id":"02vFf7HBoJFq","colab_type":"code","colab":{}},"source":["import numpy as np\n","import sklearn "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bXYj_1fHoJFs","colab_type":"text"},"source":["### NumPy Basics\n","\n","Great. Let's move on to our next topic: getting a handle on NumPy basics. You can think of NumPy as sort of like a MATLAB for Python (if that helps). The main object is multidimensional arrays, and these come in particularly handy when working with data and machine learning algorithms.\n","\n","Let's create a 2x4 array containing the numbers 1 through 8 and conduct some basic operations on it.  \n","**>> Run the code in the next cell to create and print the array.***"]},{"cell_type":"code","metadata":{"id":"xs3V4laeoJFt","colab_type":"code","outputId":"27342dc8-cf89-471d-82bf-dad3e489d3d0","executionInfo":{"status":"ok","timestamp":1574354438140,"user_tz":300,"elapsed":1386,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["array = np.arange(8).reshape(2,4)\n","array"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 1, 2, 3],\n","       [4, 5, 6, 7]])"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"xICCkhfNoJFu","colab_type":"text"},"source":["We can access the shape, number of dimensions, data type, and number of elements in our array as follows:  \n","*(Tip: use \"print()\" when you want a cell to output more than one thing, or you want to append text to your output, otherwise the cell will output the last object you call, as in the cell above)*"]},{"cell_type":"code","metadata":{"id":"ncoFbUrloJFv","colab_type":"code","outputId":"7dbdc0b6-aff5-4dd3-b00e-26c40110b679","executionInfo":{"status":"ok","timestamp":1574354438141,"user_tz":300,"elapsed":1368,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["print (\"Shape:\", array.shape)\n","print (\"Dimensions:\", array.ndim)\n","print (\"Data type:\" , array.dtype.name)\n","print (\"Number of elements:\", array.size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Shape: (2, 4)\n","Dimensions: 2\n","Data type: int64\n","Number of elements: 8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f_9lG_HUoJFw","colab_type":"text"},"source":["If we have a Python list containing a set of numbers, we can use it to create an array:  \n","*(Tip: if you click on a function call, such as array(), and press \"shift+tab\" the Notebook will provide you all the details of the function)*"]},{"cell_type":"code","metadata":{"id":"YBuAwh7ZoJFw","colab_type":"code","outputId":"d3d019aa-8ba3-402c-ac7e-22940349bd77","executionInfo":{"status":"ok","timestamp":1574354438141,"user_tz":300,"elapsed":1349,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["mylist = [0, 1, 1, 2, 3, 5, 8, 13, 21]\n","myarray = np.array(mylist)\n","myarray"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0,  1,  1,  2,  3,  5,  8, 13, 21])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"VuaWRVPzoJFy","colab_type":"text"},"source":["And we can do it for nested lists as well, creating multidimensional NumPy arrays:"]},{"cell_type":"markdown","metadata":{"id":"CWwmlkg7uS4x","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"phcNKMipoJFy","colab_type":"code","outputId":"c89872a7-701f-4d76-ba4b-97692af3903e","executionInfo":{"status":"ok","timestamp":1574354438142,"user_tz":300,"elapsed":1330,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["my2dlist = [[1,2,3],[4,5,6]]\n","my2darray = np.array(my2dlist)\n","my2darray"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 2, 3],\n","       [4, 5, 6]])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"eg4tCbtDoJF0","colab_type":"text"},"source":["We can also index and slice NumPy arrays like we would do with a Python list or another container object as follows:"]},{"cell_type":"code","metadata":{"id":"5Lud5Oz6oJF0","colab_type":"code","outputId":"5271bb9c-1fbb-41b5-e65e-4385770004f6","executionInfo":{"status":"ok","timestamp":1574354438142,"user_tz":300,"elapsed":1311,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["array = np.arange(10)\n","print (\"Originally: \", array)\n","print (\"First four elements: \", array[:4])\n","print (\"After the first four elements: \", array[4:])\n","print (\"The last element: \", array[-1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Originally:  [0 1 2 3 4 5 6 7 8 9]\n","First four elements:  [0 1 2 3]\n","After the first four elements:  [4 5 6 7 8 9]\n","The last element:  9\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jk9CDc_moJF2","colab_type":"text"},"source":["And we can index/slice multidimensional arrays, too."]},{"cell_type":"code","metadata":{"id":"L4gkgltBoJF2","colab_type":"code","outputId":"13b5bd4e-1bab-429b-d9ef-e24e3206b724","executionInfo":{"status":"ok","timestamp":1574354438143,"user_tz":300,"elapsed":1294,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["array = np.array([[1,2,3],[4,5,6]])\n","print (\"Originally: \", array)\n","print (\"First row only: \", array[0])\n","print (\"First column only: \", array[:,0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Originally:  [[1 2 3]\n"," [4 5 6]]\n","First row only:  [1 2 3]\n","First column only:  [1 4]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4kimFdIJoJF5","colab_type":"text"},"source":["#### Sneak preview\n","\n","Often, when designing a machine learning classifier, it can be useful to compare an array of predictions (0 or 1 values) to another array of true values. We can do this pretty easily in NumPy to compute the *accuracy* (e.g., the number of values that are the same), for example, as follows:"]},{"cell_type":"code","metadata":{"id":"UrVyjSiYoJF6","colab_type":"code","outputId":"5c4c6f32-d027-4986-f47e-f9903cbe51ae","executionInfo":{"status":"ok","timestamp":1574354438143,"user_tz":300,"elapsed":1276,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["true_values = [0, 0, 1, 1, 1, 1, 1, 0, 1, 0]\n","predictions = [0, 0, 0, 1, 1, 1, 0, 1, 1, 0]\n","\n","true_values_array = np.array(true_values)\n","predictions_array = np.array(predictions)\n","\n","accuracy = np.sum(true_values_array == predictions_array) / true_values_array.size\n","print (\"Accuracy: \", accuracy * 100, \"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy:  70.0 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NTrKw3aEoJF7","colab_type":"text"},"source":["In the previous cell, we took two Python lists, converted them to NumPy arrays, and then used a combination of np.sum() and .size to compute the accuracy (proportion of elements that are pairwise equal). A tiny bit more advanced, but demonstrates the power of NumPy arrays.\n","\n","You'll notice we didn't used nested loops to conduct the comparison, but instead used the np.sum() function. This is an example of a vectorized operation within NumPy that is much more efficient when dealing with large datasets."]},{"cell_type":"markdown","metadata":{"id":"DZzw94WdoJF8","colab_type":"text"},"source":["### Pandas basics\n","\n","Pandas is an incredibly useful library that allows us to work with large datasets in Python. It contains myriad useful tools, and is highly compatible with other libraries like Scikit-learn, so you don't have to spend any time getting the two to play nicely together.\n","\n","First we are going to load a dataset with Pandas:"]},{"cell_type":"code","metadata":{"id":"Z8Nr62k7oJF8","colab_type":"code","outputId":"f4d088d3-7510-490a-f85d-7ae3555e18ce","executionInfo":{"status":"ok","timestamp":1576606250989,"user_tz":300,"elapsed":5954,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["!pip install wget"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=24afff1e01f73354908d5b08bf6efd73b40615bf52f3bc73308226692273da2a\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TFs45of3oJF9","colab_type":"code","outputId":"6dfcf0d4-98b7-49a2-a532-91baa808cfbf","executionInfo":{"status":"ok","timestamp":1574354443967,"user_tz":300,"elapsed":7062,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import wget\n","\n","wget.download(\n","    'https://github.com/alexwolson/APS1070_data/raw/master/arabica_data.csv',\n","    'arabica_data.csv'\n",")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'arabica_data.csv'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"PrgXCIXeoJF_","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","df = pd.read_csv('arabica_data.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BNyU-L7hoJGA","colab_type":"text"},"source":["With Pandas, the main object we work with is referred to as a _DataFrame_ (hence calling our object here df). A DataFrame stores our dataset in a way that immediately gives us a lot of power to interact with it. If you just put the DataFrame in a cell on its own, you instantly get a clear, easy to read preview of the data you have:"]},{"cell_type":"code","metadata":{"id":"mwyULfgooJGB","colab_type":"code","outputId":"34385be7-f134-47ad-a74c-4bac4b2dcaf1","executionInfo":{"status":"ok","timestamp":1574354444087,"user_tz":300,"elapsed":7160,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["df"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Acidity</th>\n","      <th>Aftertaste</th>\n","      <th>Aroma</th>\n","      <th>Bag Weight</th>\n","      <th>Balance</th>\n","      <th>Body</th>\n","      <th>Category.One.Defects</th>\n","      <th>Category.Two.Defects</th>\n","      <th>Clean Cup</th>\n","      <th>Color</th>\n","      <th>Company</th>\n","      <th>Country of Origin</th>\n","      <th>Cupper Points</th>\n","      <th>Expiration</th>\n","      <th>Farm Name</th>\n","      <th>Flavor</th>\n","      <th>Grading Date</th>\n","      <th>Harvest Year</th>\n","      <th>ICO Number</th>\n","      <th>In-Country Partner</th>\n","      <th>Mill</th>\n","      <th>Moisture</th>\n","      <th>Number of Bags</th>\n","      <th>Processing Method</th>\n","      <th>Producer</th>\n","      <th>Region</th>\n","      <th>Species</th>\n","      <th>Sweetness</th>\n","      <th>Uniformity</th>\n","      <th>Variety</th>\n","      <th>altitude_high_meters</th>\n","      <th>altitude_low_meters</th>\n","      <th>altitude_mean_meters</th>\n","      <th>quality_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>8.75</td>\n","      <td>8.67</td>\n","      <td>8.67</td>\n","      <td>60 kg</td>\n","      <td>8.42</td>\n","      <td>8.50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>metad agricultural developmet plc</td>\n","      <td>Ethiopia</td>\n","      <td>8.75</td>\n","      <td>April 3rd, 2016</td>\n","      <td>METAD PLC</td>\n","      <td>8.83</td>\n","      <td>April 4th, 2015</td>\n","      <td>2014</td>\n","      <td>2014/2015</td>\n","      <td>METAD Agricultural Development plc</td>\n","      <td>metad plc</td>\n","      <td>0.12</td>\n","      <td>300</td>\n","      <td>Washed / Wet</td>\n","      <td>METAD PLC</td>\n","      <td>guji-hambela</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>NaN</td>\n","      <td>2200.00</td>\n","      <td>1950.00</td>\n","      <td>2075.00</td>\n","      <td>90.58</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>8.58</td>\n","      <td>8.50</td>\n","      <td>8.75</td>\n","      <td>60 kg</td>\n","      <td>8.42</td>\n","      <td>8.42</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>metad agricultural developmet plc</td>\n","      <td>Ethiopia</td>\n","      <td>8.58</td>\n","      <td>April 3rd, 2016</td>\n","      <td>METAD PLC</td>\n","      <td>8.67</td>\n","      <td>April 4th, 2015</td>\n","      <td>2014</td>\n","      <td>2014/2015</td>\n","      <td>METAD Agricultural Development plc</td>\n","      <td>metad plc</td>\n","      <td>0.12</td>\n","      <td>300</td>\n","      <td>Washed / Wet</td>\n","      <td>METAD PLC</td>\n","      <td>guji-hambela</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Other</td>\n","      <td>2200.00</td>\n","      <td>1950.00</td>\n","      <td>2075.00</td>\n","      <td>89.92</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>8.42</td>\n","      <td>8.42</td>\n","      <td>8.42</td>\n","      <td>1</td>\n","      <td>8.42</td>\n","      <td>8.33</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Guatemala</td>\n","      <td>9.25</td>\n","      <td>May 31st, 2011</td>\n","      <td>San Marcos Barrancas \"San Cristobal Cuch</td>\n","      <td>8.50</td>\n","      <td>May 31st, 2010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>NaN</td>\n","      <td>0.00</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Bourbon</td>\n","      <td>1800.00</td>\n","      <td>1600.00</td>\n","      <td>1700.00</td>\n","      <td>89.75</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>8.42</td>\n","      <td>8.42</td>\n","      <td>8.17</td>\n","      <td>60 kg</td>\n","      <td>8.25</td>\n","      <td>8.50</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>yidnekachew debessa coffee plantation</td>\n","      <td>Ethiopia</td>\n","      <td>8.67</td>\n","      <td>March 25th, 2016</td>\n","      <td>Yidnekachew Dabessa Coffee Plantation</td>\n","      <td>8.58</td>\n","      <td>March 26th, 2015</td>\n","      <td>2014</td>\n","      <td>NaN</td>\n","      <td>METAD Agricultural Development plc</td>\n","      <td>wolensu</td>\n","      <td>0.11</td>\n","      <td>320</td>\n","      <td>Natural / Dry</td>\n","      <td>Yidnekachew Dabessa Coffee Plantation</td>\n","      <td>oromia</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>NaN</td>\n","      <td>2200.00</td>\n","      <td>1800.00</td>\n","      <td>2000.00</td>\n","      <td>89.00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>8.50</td>\n","      <td>8.25</td>\n","      <td>8.25</td>\n","      <td>60 kg</td>\n","      <td>8.33</td>\n","      <td>8.42</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>metad agricultural developmet plc</td>\n","      <td>Ethiopia</td>\n","      <td>8.58</td>\n","      <td>April 3rd, 2016</td>\n","      <td>METAD PLC</td>\n","      <td>8.50</td>\n","      <td>April 4th, 2015</td>\n","      <td>2014</td>\n","      <td>2014/2015</td>\n","      <td>METAD Agricultural Development plc</td>\n","      <td>metad plc</td>\n","      <td>0.12</td>\n","      <td>300</td>\n","      <td>Washed / Wet</td>\n","      <td>METAD PLC</td>\n","      <td>guji-hambela</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Other</td>\n","      <td>2200.00</td>\n","      <td>1950.00</td>\n","      <td>2075.00</td>\n","      <td>88.83</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1306</th>\n","      <td>1306</td>\n","      <td>6.50</td>\n","      <td>6.17</td>\n","      <td>7.00</td>\n","      <td>1 kg</td>\n","      <td>6.17</td>\n","      <td>6.67</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.00</td>\n","      <td>Green</td>\n","      <td>cadexsa</td>\n","      <td>Mexico</td>\n","      <td>6.75</td>\n","      <td>May 15th, 2015</td>\n","      <td>EL CENTENARIO</td>\n","      <td>6.33</td>\n","      <td>September 17th, 2012</td>\n","      <td>2012</td>\n","      <td>1104328663</td>\n","      <td>AMECAFE</td>\n","      <td>cadexsa</td>\n","      <td>0.10</td>\n","      <td>12</td>\n","      <td>Washed / Wet</td>\n","      <td>Omar Acosta</td>\n","      <td>marcala</td>\n","      <td>Arabica</td>\n","      <td>8.00</td>\n","      <td>8.00</td>\n","      <td>Catuai</td>\n","      <td>1450.00</td>\n","      <td>1450.00</td>\n","      <td>1450.00</td>\n","      <td>68.33</td>\n","    </tr>\n","    <tr>\n","      <th>1307</th>\n","      <td>1307</td>\n","      <td>7.42</td>\n","      <td>6.25</td>\n","      <td>7.08</td>\n","      <td>2 kg</td>\n","      <td>6.75</td>\n","      <td>7.25</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>6.00</td>\n","      <td>None</td>\n","      <td>terra mia</td>\n","      <td>Haiti</td>\n","      <td>6.42</td>\n","      <td>September 17th, 2013</td>\n","      <td>200 farms</td>\n","      <td>6.83</td>\n","      <td>May 24th, 2012</td>\n","      <td>2012</td>\n","      <td>NaN</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>la esperanza, municipio juchique de ferrer, ve...</td>\n","      <td>0.11</td>\n","      <td>1</td>\n","      <td>Natural / Dry</td>\n","      <td>JUAN CARLOS GARCÍA LOPEZ</td>\n","      <td>juchique de ferrer</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Bourbon</td>\n","      <td>900.00</td>\n","      <td>900.00</td>\n","      <td>900.00</td>\n","      <td>67.92</td>\n","    </tr>\n","    <tr>\n","      <th>1308</th>\n","      <td>1308</td>\n","      <td>6.67</td>\n","      <td>6.42</td>\n","      <td>6.75</td>\n","      <td>69 kg</td>\n","      <td>6.67</td>\n","      <td>7.08</td>\n","      <td>8</td>\n","      <td>16</td>\n","      <td>6.00</td>\n","      <td>Blue-Green</td>\n","      <td>haiti coffee</td>\n","      <td>Nicaragua</td>\n","      <td>6.17</td>\n","      <td>May 24th, 2013</td>\n","      <td>Finca Las Marías</td>\n","      <td>6.58</td>\n","      <td>June 6th, 2017</td>\n","      <td>2016</td>\n","      <td>017-053-0211/ 017-053-0212</td>\n","      <td>Instituto Hondureño del Café</td>\n","      <td>coeb koperativ ekselsyo basen (350 members)</td>\n","      <td>0.14</td>\n","      <td>550</td>\n","      <td>Other</td>\n","      <td>COEB Koperativ Ekselsyo Basen</td>\n","      <td>department d'artibonite , haiti</td>\n","      <td>Arabica</td>\n","      <td>6.00</td>\n","      <td>9.33</td>\n","      <td>Typica</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>63.08</td>\n","    </tr>\n","    <tr>\n","      <th>1309</th>\n","      <td>1309</td>\n","      <td>6.25</td>\n","      <td>6.33</td>\n","      <td>7.25</td>\n","      <td>1 kg</td>\n","      <td>6.08</td>\n","      <td>6.42</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>1.33</td>\n","      <td>Green</td>\n","      <td>exportadora atlantic s.a</td>\n","      <td>Guatemala</td>\n","      <td>6.67</td>\n","      <td>June 6th, 2018</td>\n","      <td>FINCA EL LIMON</td>\n","      <td>6.58</td>\n","      <td>May 24th, 2012</td>\n","      <td>2012</td>\n","      <td>11/853/165</td>\n","      <td>Asociacion Nacional Del Café</td>\n","      <td>beneficio atlantic condega</td>\n","      <td>0.13</td>\n","      <td>275</td>\n","      <td>Washed / Wet</td>\n","      <td>Teófilo Narváez</td>\n","      <td>jalapa</td>\n","      <td>Arabica</td>\n","      <td>6.00</td>\n","      <td>6.00</td>\n","      <td>Caturra</td>\n","      <td>1100.00</td>\n","      <td>1100.00</td>\n","      <td>1100.00</td>\n","      <td>59.83</td>\n","    </tr>\n","    <tr>\n","      <th>1310</th>\n","      <td>1310</td>\n","      <td>7.67</td>\n","      <td>6.67</td>\n","      <td>7.50</td>\n","      <td>0 lbs</td>\n","      <td>6.67</td>\n","      <td>7.33</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.00</td>\n","      <td>Green</td>\n","      <td>unicafe</td>\n","      <td>Ethiopia</td>\n","      <td>6.00</td>\n","      <td>May 24th, 2013</td>\n","      <td>TEST</td>\n","      <td>6.67</td>\n","      <td>June 18th, 2010</td>\n","      <td>TEST</td>\n","      <td>TEST</td>\n","      <td>Ethiopia Commodity Exchange</td>\n","      <td>beneficio serben</td>\n","      <td>0.10</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>WILLIAM ESTUARDO MARTINEZ PACHECO</td>\n","      <td>nuevo oriente</td>\n","      <td>Arabica</td>\n","      <td>1.33</td>\n","      <td>8.00</td>\n","      <td>Catuai</td>\n","      <td>1417.32</td>\n","      <td>1417.32</td>\n","      <td>1417.32</td>\n","      <td>43.13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1311 rows × 35 columns</p>\n","</div>"],"text/plain":["      Unnamed: 0  Acidity  ...  altitude_mean_meters  quality_score\n","0              0     8.75  ...               2075.00          90.58\n","1              1     8.58  ...               2075.00          89.92\n","2              2     8.42  ...               1700.00          89.75\n","3              3     8.42  ...               2000.00          89.00\n","4              4     8.50  ...               2075.00          88.83\n","...          ...      ...  ...                   ...            ...\n","1306        1306     6.50  ...               1450.00          68.33\n","1307        1307     7.42  ...                900.00          67.92\n","1308        1308     6.67  ...                350.00          63.08\n","1309        1309     6.25  ...               1100.00          59.83\n","1310        1310     7.67  ...               1417.32          43.13\n","\n","[1311 rows x 35 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"SRMk05QJoJGC","colab_type":"text"},"source":["But even though this is printed out well, the dataset is a bit too large for this view to be anything but overwhelming. Luckily, Pandas allows us to easily get some summary statistics about our data."]},{"cell_type":"code","metadata":{"id":"IdcIgH0roJGD","colab_type":"code","outputId":"9b70a20e-faf3-46e9-d943-f647d7dade6f","executionInfo":{"status":"ok","timestamp":1574354444207,"user_tz":300,"elapsed":7261,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":334}},"source":["df.describe()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Acidity</th>\n","      <th>Aftertaste</th>\n","      <th>Aroma</th>\n","      <th>Balance</th>\n","      <th>Body</th>\n","      <th>Category.One.Defects</th>\n","      <th>Category.Two.Defects</th>\n","      <th>Clean Cup</th>\n","      <th>Cupper Points</th>\n","      <th>Flavor</th>\n","      <th>Moisture</th>\n","      <th>Number of Bags</th>\n","      <th>Sweetness</th>\n","      <th>Uniformity</th>\n","      <th>altitude_high_meters</th>\n","      <th>altitude_low_meters</th>\n","      <th>altitude_mean_meters</th>\n","      <th>quality_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.00000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1084.000000</td>\n","      <td>1084.000000</td>\n","      <td>1084.000000</td>\n","      <td>1311.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>655.000000</td>\n","      <td>7.538764</td>\n","      <td>7.403158</td>\n","      <td>7.569527</td>\n","      <td>7.523288</td>\n","      <td>7.523387</td>\n","      <td>0.450038</td>\n","      <td>3.626240</td>\n","      <td>9.83312</td>\n","      <td>7.502441</td>\n","      <td>7.523539</td>\n","      <td>0.088963</td>\n","      <td>153.678108</td>\n","      <td>9.910900</td>\n","      <td>9.839497</td>\n","      <td>1808.751552</td>\n","      <td>1759.456703</td>\n","      <td>1784.104128</td>\n","      <td>82.148825</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>378.597412</td>\n","      <td>0.319773</td>\n","      <td>0.349945</td>\n","      <td>0.315930</td>\n","      <td>0.349174</td>\n","      <td>0.293089</td>\n","      <td>2.017571</td>\n","      <td>5.482857</td>\n","      <td>0.77135</td>\n","      <td>0.428989</td>\n","      <td>0.341817</td>\n","      <td>0.047907</td>\n","      <td>129.760079</td>\n","      <td>0.454824</td>\n","      <td>0.491508</td>\n","      <td>8767.192330</td>\n","      <td>8767.851565</td>\n","      <td>8767.021485</td>\n","      <td>2.893505</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>5.250000</td>\n","      <td>6.170000</td>\n","      <td>5.080000</td>\n","      <td>6.080000</td>\n","      <td>5.250000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>5.170000</td>\n","      <td>6.080000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.330000</td>\n","      <td>6.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>43.130000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>327.500000</td>\n","      <td>7.330000</td>\n","      <td>7.250000</td>\n","      <td>7.420000</td>\n","      <td>7.330000</td>\n","      <td>7.330000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.00000</td>\n","      <td>7.250000</td>\n","      <td>7.330000</td>\n","      <td>0.090000</td>\n","      <td>14.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>1100.000000</td>\n","      <td>1100.000000</td>\n","      <td>1100.000000</td>\n","      <td>81.170000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>655.000000</td>\n","      <td>7.500000</td>\n","      <td>7.420000</td>\n","      <td>7.580000</td>\n","      <td>7.500000</td>\n","      <td>7.500000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>10.00000</td>\n","      <td>7.500000</td>\n","      <td>7.580000</td>\n","      <td>0.110000</td>\n","      <td>170.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>1350.000000</td>\n","      <td>1310.640000</td>\n","      <td>1310.640000</td>\n","      <td>82.500000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>982.500000</td>\n","      <td>7.750000</td>\n","      <td>7.580000</td>\n","      <td>7.750000</td>\n","      <td>7.750000</td>\n","      <td>7.670000</td>\n","      <td>0.000000</td>\n","      <td>4.000000</td>\n","      <td>10.00000</td>\n","      <td>7.750000</td>\n","      <td>7.750000</td>\n","      <td>0.120000</td>\n","      <td>275.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>1650.000000</td>\n","      <td>1600.000000</td>\n","      <td>1600.000000</td>\n","      <td>83.670000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1310.000000</td>\n","      <td>8.750000</td>\n","      <td>8.670000</td>\n","      <td>8.750000</td>\n","      <td>8.750000</td>\n","      <td>8.580000</td>\n","      <td>31.000000</td>\n","      <td>55.000000</td>\n","      <td>10.00000</td>\n","      <td>10.000000</td>\n","      <td>8.830000</td>\n","      <td>0.280000</td>\n","      <td>1062.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>190164.000000</td>\n","      <td>190164.000000</td>\n","      <td>190164.000000</td>\n","      <td>90.580000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Unnamed: 0      Acidity  ...  altitude_mean_meters  quality_score\n","count  1311.000000  1311.000000  ...           1084.000000    1311.000000\n","mean    655.000000     7.538764  ...           1784.104128      82.148825\n","std     378.597412     0.319773  ...           8767.021485       2.893505\n","min       0.000000     5.250000  ...              1.000000      43.130000\n","25%     327.500000     7.330000  ...           1100.000000      81.170000\n","50%     655.000000     7.500000  ...           1310.640000      82.500000\n","75%     982.500000     7.750000  ...           1600.000000      83.670000\n","max    1310.000000     8.750000  ...         190164.000000      90.580000\n","\n","[8 rows x 19 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"Eu_NKdsUoJGE","colab_type":"text"},"source":["Let's say we want to zero in on a single column. This is done the same way that you access a dictionary entry:"]},{"cell_type":"code","metadata":{"id":"5AfhzRXIoJGE","colab_type":"code","outputId":"93a79042-0a2e-480c-bb30-cd9857d9ede2","executionInfo":{"status":"ok","timestamp":1574354444208,"user_tz":300,"elapsed":7243,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["df['Species']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       Arabica\n","1       Arabica\n","2       Arabica\n","3       Arabica\n","4       Arabica\n","         ...   \n","1306    Arabica\n","1307    Arabica\n","1308    Arabica\n","1309    Arabica\n","1310    Arabica\n","Name: Species, Length: 1311, dtype: object"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"PL32j4QcoJGF","colab_type":"text"},"source":["Using this method of column access on its own returns a `series` object - think of this as a DataFrame with only one column. If you want to get the raw values however, you can simply specify this by adding `.values` after your entry. Using this, and by putting the object in a `Set` (which does not allow duplicate entries), we can quickly see all of the possible values for any column:"]},{"cell_type":"code","metadata":{"id":"ZQLTkn5LoJGG","colab_type":"code","outputId":"4440b7f9-854e-4e1f-d3e8-46bd7670815c","executionInfo":{"status":"ok","timestamp":1574354444487,"user_tz":300,"elapsed":7503,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["set(df['Variety'].values)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Arusha',\n"," 'Blue Mountain',\n"," 'Bourbon',\n"," 'Catimor',\n"," 'Catuai',\n"," 'Caturra',\n"," 'Ethiopian Heirlooms',\n"," 'Ethiopian Yirgacheffe',\n"," 'Gesha',\n"," 'Hawaiian Kona',\n"," 'Java',\n"," 'Mandheling',\n"," 'Marigojipe',\n"," 'Moka Peaberry',\n"," 'Mundo Novo',\n"," 'Other',\n"," 'Pacamara',\n"," 'Pacas',\n"," 'Pache Comun',\n"," 'Peaberry',\n"," 'Ruiru 11',\n"," 'SL14',\n"," 'SL28',\n"," 'SL34',\n"," 'Sulawesi',\n"," 'Sumatra',\n"," 'Sumatra Lintong',\n"," 'Typica',\n"," 'Yellow Bourbon',\n"," nan}"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"6fJoOBgjoJGI","colab_type":"text"},"source":["You may notice that the final entry in this set isn't like the others - it's `nan`, which in Pandas denotes a missing entry. When working with real world datasets it's very common for entries to be missing, and there are a variety of ways of approaching a problem like this. For now, though, we are simply going to tell Pandas to drop any row that has a missing column, using the `dropna()` method."]},{"cell_type":"code","metadata":{"id":"Vy3se4KxoJGI","colab_type":"code","colab":{}},"source":["df_clean = df.dropna()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JdkOZCJloJGK","colab_type":"text"},"source":["**YOUR TURN** How many entries did we lose by dropping all `nan`s? --> SOlutions: 1311 rows to 541 rows, so we have losed 770 rows/entrie\n","\n","* What percentage of entries are left in `df_clean`? ______ --> solutions: we have left 41.27% of entries in df_clean\n","* What column had the highest number of `nan` entries? (This can be done in one line - use Google!) ______ --> SOlution: Farm Name. see the code below"]},{"cell_type":"code","metadata":{"id":"TmV7ovR1w5dg","colab_type":"code","outputId":"22ce24de-2d22-4d43-cd04-b0a7fc4d18f2","executionInfo":{"status":"ok","timestamp":1574354444489,"user_tz":300,"elapsed":7484,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(df_clean)#1311 rows to 541 rows, so we have losed 770 rows/entrie"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["541"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"NJi7JpQVw3yA","colab_type":"code","outputId":"73bf5d1b-8cc9-49eb-96af-1b8aca1f0436","executionInfo":{"status":"ok","timestamp":1574354444489,"user_tz":300,"elapsed":7466,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(df_clean) / len(df)# we have left 41.27% of entries in df_clean"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.41266209000762777"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"ucfK-iV8xEIW","colab_type":"code","outputId":"1725d96b-9f94-48a7-90aa-eadc4386d422","executionInfo":{"status":"ok","timestamp":1574354444490,"user_tz":300,"elapsed":7449,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df.isna().sum().idxmax() # return the column name that has the largest number of Nan"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Farm Name'"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"_1p4DU9poJGN","colab_type":"text"},"source":["As you perform this analysis, you will probably notice that we've lost _quite a bit_ of our original data by simply dropping the `nan` values. There is another approach that we can examine, however. Instead of dropping the missing entries entirely, we can _impute_ their value using the data we do have. For a single column we can do this like so:"]},{"cell_type":"code","metadata":{"id":"9F6N5-_uoJGN","colab_type":"code","colab":{}},"source":["from sklearn.impute import SimpleImputer\n","\n","imp = SimpleImputer(\n","    missing_values=np.nan,\n","    strategy='mean',\n","    verbose=1\n",")\n","\n","imp.fit(\n","    df['altitude_mean_meters'].values.reshape((-1,1)) #we have to do the reshape operation because we are only using one feature.\n",")\n","\n","df['altitude_mean_meters_imputed'] = imp.transform(df['altitude_mean_meters'].values.reshape((-1,1)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mfp3D574oJGP","colab_type":"code","outputId":"16b025a3-6741-4320-88a1-14396663cdc8","executionInfo":{"status":"ok","timestamp":1574354444828,"user_tz":300,"elapsed":7766,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["df[['altitude_mean_meters','altitude_mean_meters_imputed']].head(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>altitude_mean_meters</th>\n","      <th>altitude_mean_meters_imputed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2075.0</td>\n","      <td>2075.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2075.0</td>\n","      <td>2075.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1700.0</td>\n","      <td>1700.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2000.0</td>\n","      <td>2000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2075.0</td>\n","      <td>2075.000000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>NaN</td>\n","      <td>1784.104128</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NaN</td>\n","      <td>1784.104128</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1635.0</td>\n","      <td>1635.000000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1635.0</td>\n","      <td>1635.000000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1822.5</td>\n","      <td>1822.500000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   altitude_mean_meters  altitude_mean_meters_imputed\n","0                2075.0                   2075.000000\n","1                2075.0                   2075.000000\n","2                1700.0                   1700.000000\n","3                2000.0                   2000.000000\n","4                2075.0                   2075.000000\n","5                   NaN                   1784.104128\n","6                   NaN                   1784.104128\n","7                1635.0                   1635.000000\n","8                1635.0                   1635.000000\n","9                1822.5                   1822.500000"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"14A5mPi7oJGQ","colab_type":"text"},"source":["OK, great! Now we have replaced the useless NaN values with the average height. While this obviously isn't as good as original data, in a lot of situations this can be a step up from losing rows entirely. "]},{"cell_type":"markdown","metadata":{"id":"DK7eW8caoJGR","colab_type":"text"},"source":["Sophisticated analysis can be done in only a few lines using Pandas. Let's say that we want to get the average coffee rating by country. First, we can use the `groupby` method to automatically collect the results by country. Then, we can select the column we want - `quality_score` - and calculate its mean the same way we would using NumPy:"]},{"cell_type":"code","metadata":{"id":"xx0KTeIxoJGR","colab_type":"code","outputId":"95aef960-7973-457b-cd1d-aac5e64a4d9a","executionInfo":{"status":"ok","timestamp":1574354444828,"user_tz":300,"elapsed":7748,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["df_clean.groupby('Country of Origin')['quality_score'].mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Country of Origin\n","Brazil                          82.330725\n","China                           80.868000\n","Colombia                        82.932000\n","Costa Rica                      83.090000\n","El Salvador                     82.804545\n","Ethiopia                        87.792500\n","Guatemala                       81.957832\n","Haiti                           80.750000\n","Honduras                        81.010476\n","Indonesia                       81.524286\n","Kenya                           85.415000\n","Laos                            82.000000\n","Malawi                          81.711818\n","Mexico                          80.246087\n","Myanmar                         80.666667\n","Nicaragua                       79.333000\n","Panama                          81.750000\n","Peru                            77.000000\n","Philippines                     80.312500\n","Taiwan                          82.462895\n","Tanzania, United Republic Of    82.411724\n","Uganda                          83.778333\n","Name: quality_score, dtype: float64"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"Jzvh5MU-oJGS","colab_type":"text"},"source":["This is certainly interesting, but it could be presented better. First, all of the ratings are pretty high (what's the highest and lowest rating?). Let's standardize to unit mean and variance so that we can tell the difference more easily. We'll just do that on our subset here for now, but you can apply it to the entire dataset too!"]},{"cell_type":"markdown","metadata":{"id":"vYl7OB3F9h5z","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"CBUOQRA9oJGS","colab_type":"code","outputId":"811a6c8f-fc12-40d2-b6c0-95aa9d08b2b2","executionInfo":{"status":"ok","timestamp":1574354444829,"user_tz":300,"elapsed":7730,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["country_means = df_clean.groupby('Country of Origin')['quality_score'].mean()\n","mu,si = country_means.mean(), country_means.std() #Calculate the overall mean and standard deviation of the quality scores\n","country_means -= mu #Subtract the mean from every entry\n","country_means /= si #Divide every entry by the standard deviation\n","country_means"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Country of Origin\n","Brazil                          0.194625\n","China                          -0.491541\n","Colombia                        0.476684\n","Costa Rica                      0.550802\n","El Salvador                     0.416895\n","Ethiopia                        2.756749\n","Guatemala                       0.019701\n","Haiti                          -0.546895\n","Honduras                       -0.424705\n","Indonesia                      -0.183677\n","Kenya                           1.641462\n","Laos                            0.039482\n","Malawi                         -0.095705\n","Mexico                         -0.783281\n","Myanmar                        -0.585987\n","Nicaragua                      -1.211611\n","Panama                         -0.077794\n","Peru                           -2.306024\n","Philippines                    -0.752127\n","Taiwan                          0.256626\n","Tanzania, United Republic Of    0.232622\n","Uganda                          0.873700\n","Name: quality_score, dtype: float64"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"2dFpdBvuoJGU","colab_type":"text"},"source":["This is a lot clearer! Finally, let's sort this list so that it's easier to compare entries."]},{"cell_type":"code","metadata":{"id":"Ij1F28KzoJGU","colab_type":"code","outputId":"68fb6f1b-0946-47e3-80ab-1857f404c95f","executionInfo":{"status":"ok","timestamp":1574354444830,"user_tz":300,"elapsed":7712,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["country_means.sort_values()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Country of Origin\n","Peru                           -2.306024\n","Nicaragua                      -1.211611\n","Mexico                         -0.783281\n","Philippines                    -0.752127\n","Myanmar                        -0.585987\n","Haiti                          -0.546895\n","China                          -0.491541\n","Honduras                       -0.424705\n","Indonesia                      -0.183677\n","Malawi                         -0.095705\n","Panama                         -0.077794\n","Guatemala                       0.019701\n","Laos                            0.039482\n","Brazil                          0.194625\n","Tanzania, United Republic Of    0.232622\n","Taiwan                          0.256626\n","El Salvador                     0.416895\n","Colombia                        0.476684\n","Costa Rica                      0.550802\n","Uganda                          0.873700\n","Kenya                           1.641462\n","Ethiopia                        2.756749\n","Name: quality_score, dtype: float64"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"NoMBMddpoJGW","colab_type":"text"},"source":["Finally, we'll look at indexing using Pandas. Let's say that we want to only look at the coffee entries from Taiwan. We can use the following syntax to identify those rows:"]},{"cell_type":"code","metadata":{"id":"Rft2VN4soJGW","colab_type":"code","outputId":"4c004832-53e1-4e4c-a020-faabf4cb2ccb","executionInfo":{"status":"ok","timestamp":1574354444952,"user_tz":300,"elapsed":7815,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["df_clean[df_clean['Country of Origin'] == 'Taiwan']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Acidity</th>\n","      <th>Aftertaste</th>\n","      <th>Aroma</th>\n","      <th>Bag Weight</th>\n","      <th>Balance</th>\n","      <th>Body</th>\n","      <th>Category.One.Defects</th>\n","      <th>Category.Two.Defects</th>\n","      <th>Clean Cup</th>\n","      <th>Color</th>\n","      <th>Company</th>\n","      <th>Country of Origin</th>\n","      <th>Cupper Points</th>\n","      <th>Expiration</th>\n","      <th>Farm Name</th>\n","      <th>Flavor</th>\n","      <th>Grading Date</th>\n","      <th>Harvest Year</th>\n","      <th>ICO Number</th>\n","      <th>In-Country Partner</th>\n","      <th>Mill</th>\n","      <th>Moisture</th>\n","      <th>Number of Bags</th>\n","      <th>Processing Method</th>\n","      <th>Producer</th>\n","      <th>Region</th>\n","      <th>Species</th>\n","      <th>Sweetness</th>\n","      <th>Uniformity</th>\n","      <th>Variety</th>\n","      <th>altitude_high_meters</th>\n","      <th>altitude_low_meters</th>\n","      <th>altitude_mean_meters</th>\n","      <th>quality_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>29</th>\n","      <td>29</td>\n","      <td>8.25</td>\n","      <td>8.00</td>\n","      <td>8.00</td>\n","      <td>50 kg</td>\n","      <td>8.17</td>\n","      <td>8.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>8.17</td>\n","      <td>May 18th, 2017</td>\n","      <td>Tsoustructive Garden 鄒築園</td>\n","      <td>8.00</td>\n","      <td>May 18th, 2016</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>tsoustructive garden 鄒築園</td>\n","      <td>0.00</td>\n","      <td>20</td>\n","      <td>Pulped natural / honey</td>\n","      <td>FANG,ZHENG-LUN 方政倫</td>\n","      <td>leye, alishan township, chiayi county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Sumatra</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>86.58</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>43</td>\n","      <td>8.08</td>\n","      <td>7.75</td>\n","      <td>8.08</td>\n","      <td>15 kg</td>\n","      <td>7.83</td>\n","      <td>7.75</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>8.42</td>\n","      <td>June 9th, 2016</td>\n","      <td>Sunshine Valley Estate 向陽高山咖啡</td>\n","      <td>8.17</td>\n","      <td>June 10th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>sunshine valley estate 向陽高山咖啡</td>\n","      <td>0.12</td>\n","      <td>10</td>\n","      <td>Semi-washed / Semi-pulped</td>\n","      <td>LIN YEN CHIEN 林言謙</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Bourbon</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>86.08</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>108</td>\n","      <td>7.58</td>\n","      <td>8.00</td>\n","      <td>7.67</td>\n","      <td>40 kg</td>\n","      <td>7.92</td>\n","      <td>8.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.92</td>\n","      <td>June 8th, 2016</td>\n","      <td>Baishengcun Coffee 百勝村咖啡莊園</td>\n","      <td>7.83</td>\n","      <td>June 9th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>baishengcun coffee 百勝村咖啡莊園</td>\n","      <td>0.11</td>\n","      <td>20</td>\n","      <td>Semi-washed / Semi-pulped</td>\n","      <td>SU CHUEN SHIAN 蘇春賢</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>84.92</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>115</td>\n","      <td>7.83</td>\n","      <td>7.83</td>\n","      <td>7.92</td>\n","      <td>20 kg</td>\n","      <td>7.83</td>\n","      <td>7.83</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>8.00</td>\n","      <td>May 18th, 2017</td>\n","      <td>Shi Fang Yuan 十方源</td>\n","      <td>7.58</td>\n","      <td>May 18th, 2016</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>shi fang yuan 十方源</td>\n","      <td>0.00</td>\n","      <td>10</td>\n","      <td>Natural / Dry</td>\n","      <td>Wang Chao Yung 王超永</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>84.83</td>\n","    </tr>\n","    <tr>\n","      <th>175</th>\n","      <td>175</td>\n","      <td>8.00</td>\n","      <td>7.75</td>\n","      <td>7.83</td>\n","      <td>2 kg</td>\n","      <td>7.75</td>\n","      <td>7.50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>tropica galliard</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>July 10th, 2014</td>\n","      <td>Tropica Galliard</td>\n","      <td>7.83</td>\n","      <td>July 10th, 2013</td>\n","      <td>2012</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>tropica galliard</td>\n","      <td>0.11</td>\n","      <td>2</td>\n","      <td>Washed / Wet</td>\n","      <td>Kao Ming Lee</td>\n","      <td>mountain ali, taiwan</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>84.42</td>\n","    </tr>\n","    <tr>\n","      <th>191</th>\n","      <td>191</td>\n","      <td>7.67</td>\n","      <td>7.75</td>\n","      <td>7.92</td>\n","      <td>5 kg</td>\n","      <td>7.83</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.67</td>\n","      <td>August 10th, 2018</td>\n","      <td>馨晴咖啡 Good Mood Coffee</td>\n","      <td>7.75</td>\n","      <td>August 10th, 2017</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>馨晴咖啡 good mood coffee</td>\n","      <td>0.12</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>黃美桃 Huang Mei Tao</td>\n","      <td>國姓鄉 guoshing township</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>84.25</td>\n","    </tr>\n","    <tr>\n","      <th>233</th>\n","      <td>233</td>\n","      <td>7.67</td>\n","      <td>7.67</td>\n","      <td>7.58</td>\n","      <td>20 kg</td>\n","      <td>7.83</td>\n","      <td>7.75</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>10.00</td>\n","      <td>Bluish-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.92</td>\n","      <td>May 18th, 2017</td>\n","      <td>CHANG YU LIANG 張玉良</td>\n","      <td>7.67</td>\n","      <td>May 18th, 2016</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>chang yu liang 張玉良</td>\n","      <td>0.10</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>CHANG YU LIANG 張玉良</td>\n","      <td>nanxi dist., tainan city 臺南市楠西區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>968.00</td>\n","      <td>968.00</td>\n","      <td>968.00</td>\n","      <td>84.08</td>\n","    </tr>\n","    <tr>\n","      <th>262</th>\n","      <td>262</td>\n","      <td>7.75</td>\n","      <td>7.83</td>\n","      <td>7.83</td>\n","      <td>50 kg</td>\n","      <td>7.75</td>\n","      <td>7.83</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.83</td>\n","      <td>May 18th, 2017</td>\n","      <td>Tsoustructive Garden 鄒築園</td>\n","      <td>7.75</td>\n","      <td>May 18th, 2016</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>tsoustructive garden 鄒築園</td>\n","      <td>0.11</td>\n","      <td>20</td>\n","      <td>Washed / Wet</td>\n","      <td>FANG,ZHENG-LUN 方政倫</td>\n","      <td>leye, alishan township, chiayi county 嘉義阿里山樂野村</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>9.33</td>\n","      <td>Typica</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>83.92</td>\n","    </tr>\n","    <tr>\n","      <th>269</th>\n","      <td>269</td>\n","      <td>7.92</td>\n","      <td>7.92</td>\n","      <td>8.00</td>\n","      <td>60 kg</td>\n","      <td>7.33</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.17</td>\n","      <td>November 23rd, 2015</td>\n","      <td>神谷山莊園</td>\n","      <td>7.92</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>神谷山莊園</td>\n","      <td>0.06</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>張瑞宏</td>\n","      <td>台中和平區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>950.00</td>\n","      <td>950.00</td>\n","      <td>950.00</td>\n","      <td>83.92</td>\n","    </tr>\n","    <tr>\n","      <th>280</th>\n","      <td>280</td>\n","      <td>7.75</td>\n","      <td>7.67</td>\n","      <td>7.67</td>\n","      <td>18 kg</td>\n","      <td>7.75</td>\n","      <td>7.42</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.83</td>\n","      <td>April 29th, 2016</td>\n","      <td>鄉舍咖啡 Hometown Coffee</td>\n","      <td>7.75</td>\n","      <td>April 30th, 2015</td>\n","      <td>2014</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>鄉舍咖啡 hometown coffee</td>\n","      <td>0.00</td>\n","      <td>8</td>\n","      <td>Washed / Wet</td>\n","      <td>ZENG JIAN NAN 曾建男</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>570.00</td>\n","      <td>480.00</td>\n","      <td>525.00</td>\n","      <td>83.83</td>\n","    </tr>\n","    <tr>\n","      <th>298</th>\n","      <td>298</td>\n","      <td>7.58</td>\n","      <td>7.58</td>\n","      <td>7.67</td>\n","      <td>10 kg</td>\n","      <td>7.83</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>June 6th, 2018</td>\n","      <td>崁頭山咖啡館 (Kan Tou Mountain Coffee)</td>\n","      <td>7.67</td>\n","      <td>June 6th, 2017</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>崁頭山咖啡館 (kan tou mountain coffee)</td>\n","      <td>0.00</td>\n","      <td>10</td>\n","      <td>Natural / Dry</td>\n","      <td>曾如楓 &amp; 郭俊宏 (Tseng Ju Feng &amp; Kuo Jun Hong)</td>\n","      <td>台南市東山區 (dongshan dist., tainan city)</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>750.00</td>\n","      <td>750.00</td>\n","      <td>750.00</td>\n","      <td>83.75</td>\n","    </tr>\n","    <tr>\n","      <th>319</th>\n","      <td>319</td>\n","      <td>7.92</td>\n","      <td>7.33</td>\n","      <td>7.50</td>\n","      <td>50 kg</td>\n","      <td>7.67</td>\n","      <td>7.83</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Bluish-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>May 18th, 2017</td>\n","      <td>Tsoustructive Garden 鄒築園</td>\n","      <td>7.67</td>\n","      <td>May 18th, 2016</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>tsoustructive garden 鄒築園</td>\n","      <td>0.10</td>\n","      <td>20</td>\n","      <td>Natural / Dry</td>\n","      <td>FANG,ZHENG-LUN 方政倫</td>\n","      <td>leye, alishan township, chiayi county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Caturra</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>83.67</td>\n","    </tr>\n","    <tr>\n","      <th>425</th>\n","      <td>425</td>\n","      <td>7.50</td>\n","      <td>7.50</td>\n","      <td>7.67</td>\n","      <td>15 kg</td>\n","      <td>7.83</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.58</td>\n","      <td>June 17th, 2016</td>\n","      <td>Sunshine Valley Estate 向陽高山咖啡</td>\n","      <td>7.50</td>\n","      <td>June 18th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>sunshine valley estate 向陽高山咖啡</td>\n","      <td>0.10</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>LIN YEN CHIEN 林言謙</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Bourbon</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>83.25</td>\n","    </tr>\n","    <tr>\n","      <th>426</th>\n","      <td>426</td>\n","      <td>7.58</td>\n","      <td>7.75</td>\n","      <td>7.92</td>\n","      <td>60 kg</td>\n","      <td>7.33</td>\n","      <td>7.50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.33</td>\n","      <td>November 23rd, 2015</td>\n","      <td>以勒咖啡</td>\n","      <td>7.83</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwanw台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>以勒咖啡</td>\n","      <td>0.10</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>蘇詠晴</td>\n","      <td>南投國姓</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>83.25</td>\n","    </tr>\n","    <tr>\n","      <th>483</th>\n","      <td>483</td>\n","      <td>7.83</td>\n","      <td>7.50</td>\n","      <td>7.83</td>\n","      <td>60 kg</td>\n","      <td>7.25</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>May 18th, 2016</td>\n","      <td>Kan Tou Mountain Coffee 崁頭山咖啡館</td>\n","      <td>7.92</td>\n","      <td>May 19th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>kan tou mountain coffee 崁頭山咖啡館</td>\n","      <td>0.00</td>\n","      <td>20</td>\n","      <td>Natural / Dry</td>\n","      <td>Tseng ju feng / Kuo jun hong 曾如楓 / 郭俊宏</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>9.33</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>700.00</td>\n","      <td>750.00</td>\n","      <td>83.08</td>\n","    </tr>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>7.58</td>\n","      <td>7.83</td>\n","      <td>7.92</td>\n","      <td>60 kg</td>\n","      <td>7.25</td>\n","      <td>7.33</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.17</td>\n","      <td>November 23rd, 2015</td>\n","      <td>雅慕伊</td>\n","      <td>7.92</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>雅慕伊</td>\n","      <td>0.08</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>雅慕伊</td>\n","      <td>嘉義阿里山</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>83.00</td>\n","    </tr>\n","    <tr>\n","      <th>536</th>\n","      <td>536</td>\n","      <td>7.67</td>\n","      <td>7.25</td>\n","      <td>7.17</td>\n","      <td>20 kg</td>\n","      <td>7.58</td>\n","      <td>7.67</td>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>June 28th, 2017</td>\n","      <td>Shi Fang Yuan 十方源</td>\n","      <td>7.83</td>\n","      <td>June 28th, 2016</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>shi fang yuan 十方源</td>\n","      <td>0.09</td>\n","      <td>10</td>\n","      <td>Natural / Dry</td>\n","      <td>Wang Chao Yung 王超永</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Caturra</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>82.92</td>\n","    </tr>\n","    <tr>\n","      <th>538</th>\n","      <td>538</td>\n","      <td>7.33</td>\n","      <td>7.67</td>\n","      <td>7.50</td>\n","      <td>2 kg</td>\n","      <td>7.75</td>\n","      <td>7.50</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.58</td>\n","      <td>September 6th, 2016</td>\n","      <td>佐佑品咖啡莊園</td>\n","      <td>7.58</td>\n","      <td>September 7th, 2015</td>\n","      <td>2014</td>\n","      <td>123</td>\n","      <td>Blossom Valley International</td>\n","      <td>誼鎂有限公司</td>\n","      <td>0.00</td>\n","      <td>11</td>\n","      <td>Natural / Dry</td>\n","      <td>許文郎</td>\n","      <td>台東太麻里</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>775.00</td>\n","      <td>775.00</td>\n","      <td>775.00</td>\n","      <td>82.92</td>\n","    </tr>\n","    <tr>\n","      <th>585</th>\n","      <td>585</td>\n","      <td>7.67</td>\n","      <td>7.33</td>\n","      <td>7.83</td>\n","      <td>10 kg</td>\n","      <td>7.67</td>\n","      <td>7.58</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.67</td>\n","      <td>June 1st, 2018</td>\n","      <td>大鋤花間 (HOE Vs. FLOWER COFFEE FARM)</td>\n","      <td>7.67</td>\n","      <td>June 1st, 2017</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>大鋤花間 (hoe vs. flower coffee farm)</td>\n","      <td>0.00</td>\n","      <td>8</td>\n","      <td>Natural / Dry</td>\n","      <td>林俊吉( Lin, Chun-Chi)</td>\n","      <td>台南市東山區( dongshan dist., tainan city)</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>9.33</td>\n","      <td>Yellow Bourbon</td>\n","      <td>650.00</td>\n","      <td>650.00</td>\n","      <td>650.00</td>\n","      <td>82.75</td>\n","    </tr>\n","    <tr>\n","      <th>617</th>\n","      <td>617</td>\n","      <td>7.42</td>\n","      <td>7.83</td>\n","      <td>8.00</td>\n","      <td>60 kg</td>\n","      <td>7.25</td>\n","      <td>7.25</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.08</td>\n","      <td>November 23rd, 2015</td>\n","      <td>伊娜咖啡莊園</td>\n","      <td>7.83</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>伊娜咖啡莊園</td>\n","      <td>0.08</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>林道明</td>\n","      <td>嘉義阿里山</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>82.67</td>\n","    </tr>\n","    <tr>\n","      <th>634</th>\n","      <td>634</td>\n","      <td>7.42</td>\n","      <td>7.50</td>\n","      <td>7.67</td>\n","      <td>5 kg</td>\n","      <td>7.50</td>\n","      <td>7.58</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.50</td>\n","      <td>August 22nd, 2018</td>\n","      <td>林園咖啡 Lin Yuan Coffee</td>\n","      <td>7.42</td>\n","      <td>August 22nd, 2017</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>林園咖啡 lin yuan coffee</td>\n","      <td>0.11</td>\n","      <td>6</td>\n","      <td>Pulped natural / honey</td>\n","      <td>林文弘 Lin Wen Hong</td>\n","      <td>國姓鄉 guoshing township</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>1050.00</td>\n","      <td>1050.00</td>\n","      <td>1050.00</td>\n","      <td>82.58</td>\n","    </tr>\n","    <tr>\n","      <th>770</th>\n","      <td>770</td>\n","      <td>7.17</td>\n","      <td>7.50</td>\n","      <td>7.67</td>\n","      <td>10 kg</td>\n","      <td>7.58</td>\n","      <td>7.17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>7.58</td>\n","      <td>May 29th, 2014</td>\n","      <td>Kan Tou Mountain Coffee 崁頭山咖啡館</td>\n","      <td>7.50</td>\n","      <td>May 29th, 2013</td>\n","      <td>2012</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>kan tou mountain coffee 崁頭山咖啡館</td>\n","      <td>0.00</td>\n","      <td>80</td>\n","      <td>Washed / Wet</td>\n","      <td>Jufeng-Tseng 曾如楓</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>82.17</td>\n","    </tr>\n","    <tr>\n","      <th>801</th>\n","      <td>801</td>\n","      <td>7.42</td>\n","      <td>7.17</td>\n","      <td>7.33</td>\n","      <td>20 kg</td>\n","      <td>7.33</td>\n","      <td>7.50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>July 22nd, 2015</td>\n","      <td>You Siang Coffee FarmTainan, Taiwan 台灣台南優香咖啡</td>\n","      <td>7.50</td>\n","      <td>July 22nd, 2014</td>\n","      <td>2013</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>you siang coffee farmtainan, taiwan 台灣台南優香咖啡</td>\n","      <td>0.09</td>\n","      <td>50</td>\n","      <td>Washed / Wet</td>\n","      <td>Chen Jin Lin 陳金璘</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>600.00</td>\n","      <td>600.00</td>\n","      <td>600.00</td>\n","      <td>82.00</td>\n","    </tr>\n","    <tr>\n","      <th>806</th>\n","      <td>806</td>\n","      <td>7.42</td>\n","      <td>7.33</td>\n","      <td>7.42</td>\n","      <td>10 kg</td>\n","      <td>7.50</td>\n","      <td>8.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Bluish-Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>7.42</td>\n","      <td>June 3rd, 2014</td>\n","      <td>Gao Chun Fang 高醇坊</td>\n","      <td>7.58</td>\n","      <td>June 3rd, 2013</td>\n","      <td>2012</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>gao chun fang 高醇坊</td>\n","      <td>0.12</td>\n","      <td>30</td>\n","      <td>Washed / Wet</td>\n","      <td>Lin Huang, A-Mien 黃阿綿</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>9.33</td>\n","      <td>Typica</td>\n","      <td>700.00</td>\n","      <td>600.00</td>\n","      <td>650.00</td>\n","      <td>82.00</td>\n","    </tr>\n","    <tr>\n","      <th>844</th>\n","      <td>844</td>\n","      <td>7.25</td>\n","      <td>7.17</td>\n","      <td>7.67</td>\n","      <td>5 kg</td>\n","      <td>7.33</td>\n","      <td>7.75</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.33</td>\n","      <td>April 29th, 2016</td>\n","      <td>Gao Chun Fang 高醇坊</td>\n","      <td>7.33</td>\n","      <td>April 30th, 2015</td>\n","      <td>2014</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>gao chun fang 高醇坊</td>\n","      <td>0.00</td>\n","      <td>8</td>\n","      <td>Washed / Wet</td>\n","      <td>LIN SIN JI 林信吉</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>700.00</td>\n","      <td>700.00</td>\n","      <td>700.00</td>\n","      <td>81.83</td>\n","    </tr>\n","    <tr>\n","      <th>897</th>\n","      <td>897</td>\n","      <td>7.67</td>\n","      <td>7.25</td>\n","      <td>7.42</td>\n","      <td>50 kg</td>\n","      <td>7.25</td>\n","      <td>7.33</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.25</td>\n","      <td>July 15th, 2017</td>\n","      <td>Baishengcun Coffee 百勝村咖啡莊園</td>\n","      <td>7.42</td>\n","      <td>July 15th, 2016</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>baishengcun coffee 百勝村咖啡莊園</td>\n","      <td>0.10</td>\n","      <td>20</td>\n","      <td>Washed / Wet</td>\n","      <td>蘇晉寬 Su Jin Kuan</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>81.58</td>\n","    </tr>\n","    <tr>\n","      <th>914</th>\n","      <td>914</td>\n","      <td>7.08</td>\n","      <td>7.33</td>\n","      <td>7.50</td>\n","      <td>2 kg</td>\n","      <td>7.25</td>\n","      <td>7.58</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.33</td>\n","      <td>September 16th, 2016</td>\n","      <td>谷泉咖啡莊園</td>\n","      <td>7.42</td>\n","      <td>September 17th, 2015</td>\n","      <td>2015</td>\n","      <td>123</td>\n","      <td>Blossom Valley International</td>\n","      <td>寶島咖啡</td>\n","      <td>0.12</td>\n","      <td>123</td>\n","      <td>Natural / Dry</td>\n","      <td>劉易騰</td>\n","      <td>古坑鄉荷包村尖山坑60號</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>200.00</td>\n","      <td>160.00</td>\n","      <td>180.00</td>\n","      <td>81.50</td>\n","    </tr>\n","    <tr>\n","      <th>919</th>\n","      <td>919</td>\n","      <td>7.33</td>\n","      <td>7.67</td>\n","      <td>7.42</td>\n","      <td>20 kg</td>\n","      <td>7.50</td>\n","      <td>7.42</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>7.50</td>\n","      <td>August 18th, 2015</td>\n","      <td>Good Mood Coffee 馨晴咖啡</td>\n","      <td>7.33</td>\n","      <td>August 18th, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>good mood coffee 馨晴咖啡</td>\n","      <td>0.11</td>\n","      <td>50</td>\n","      <td>Washed / Wet</td>\n","      <td>HUANG MEI TAO 黃美桃</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>9.33</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>900.00</td>\n","      <td>900.00</td>\n","      <td>900.00</td>\n","      <td>81.50</td>\n","    </tr>\n","    <tr>\n","      <th>938</th>\n","      <td>938</td>\n","      <td>7.17</td>\n","      <td>7.42</td>\n","      <td>7.83</td>\n","      <td>60 kg</td>\n","      <td>7.08</td>\n","      <td>7.08</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.08</td>\n","      <td>November 23rd, 2015</td>\n","      <td>山彎有機咖啡農場</td>\n","      <td>7.75</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>三彎農會</td>\n","      <td>0.12</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>謝文品</td>\n","      <td>苗栗三灣</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>110.00</td>\n","      <td>110.00</td>\n","      <td>110.00</td>\n","      <td>81.42</td>\n","    </tr>\n","    <tr>\n","      <th>962</th>\n","      <td>962</td>\n","      <td>7.83</td>\n","      <td>7.67</td>\n","      <td>7.83</td>\n","      <td>50 kg</td>\n","      <td>7.75</td>\n","      <td>7.83</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>5.25</td>\n","      <td>May 18th, 2017</td>\n","      <td>Jing Jing Café 晶晶坊青山咖啡教室</td>\n","      <td>7.75</td>\n","      <td>May 18th, 2016</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>jing jing café 晶晶坊青山咖啡教室</td>\n","      <td>0.12</td>\n","      <td>20</td>\n","      <td>Natural / Dry</td>\n","      <td>Hu Guei Jing 胡桂青</td>\n","      <td>dongshan dist., tainan city 台南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>9.33</td>\n","      <td>Typica</td>\n","      <td>680.00</td>\n","      <td>680.00</td>\n","      <td>680.00</td>\n","      <td>81.25</td>\n","    </tr>\n","    <tr>\n","      <th>1004</th>\n","      <td>1004</td>\n","      <td>7.25</td>\n","      <td>7.17</td>\n","      <td>7.25</td>\n","      <td>5 kg</td>\n","      <td>7.33</td>\n","      <td>7.50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Bluish-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.33</td>\n","      <td>May 5th, 2016</td>\n","      <td>Jing Jing Café 晶晶坊青山咖啡教室</td>\n","      <td>7.17</td>\n","      <td>May 6th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>jing jing café 晶晶坊青山咖啡教室</td>\n","      <td>0.12</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>HU KUEI CHING 胡桂青</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>758.00</td>\n","      <td>758.00</td>\n","      <td>758.00</td>\n","      <td>81.00</td>\n","    </tr>\n","    <tr>\n","      <th>1021</th>\n","      <td>1021</td>\n","      <td>7.08</td>\n","      <td>7.33</td>\n","      <td>7.92</td>\n","      <td>60 kg</td>\n","      <td>7.08</td>\n","      <td>7.08</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>6.75</td>\n","      <td>November 23rd, 2015</td>\n","      <td>張文進莊園</td>\n","      <td>7.67</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>張文進莊園</td>\n","      <td>0.09</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>張文進</td>\n","      <td>台中新社</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>550.00</td>\n","      <td>550.00</td>\n","      <td>550.00</td>\n","      <td>80.92</td>\n","    </tr>\n","    <tr>\n","      <th>1080</th>\n","      <td>1080</td>\n","      <td>7.17</td>\n","      <td>7.17</td>\n","      <td>7.58</td>\n","      <td>60 kg</td>\n","      <td>7.17</td>\n","      <td>7.17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.00</td>\n","      <td>November 23rd, 2015</td>\n","      <td>春風咖啡</td>\n","      <td>7.17</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>春風咖啡</td>\n","      <td>0.14</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>曾林春英</td>\n","      <td>南投國姓</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>600.00</td>\n","      <td>600.00</td>\n","      <td>600.00</td>\n","      <td>80.42</td>\n","    </tr>\n","    <tr>\n","      <th>1115</th>\n","      <td>1115</td>\n","      <td>7.17</td>\n","      <td>7.25</td>\n","      <td>7.42</td>\n","      <td>60 kg</td>\n","      <td>7.00</td>\n","      <td>7.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.00</td>\n","      <td>November 23rd, 2015</td>\n","      <td>好自在咖啡莊園</td>\n","      <td>7.25</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>好自在咖啡莊園</td>\n","      <td>0.07</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>簡義榮</td>\n","      <td>苗栗泰安</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>850.00</td>\n","      <td>850.00</td>\n","      <td>850.00</td>\n","      <td>80.08</td>\n","    </tr>\n","    <tr>\n","      <th>1146</th>\n","      <td>1146</td>\n","      <td>7.00</td>\n","      <td>7.25</td>\n","      <td>7.08</td>\n","      <td>20 kg</td>\n","      <td>7.17</td>\n","      <td>7.17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>7.00</td>\n","      <td>July 28th, 2015</td>\n","      <td>Baijiada Coffee Farm佰加達咖啡莊園</td>\n","      <td>7.08</td>\n","      <td>July 28th, 2014</td>\n","      <td>2013</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>baijiada coffee farm佰加達咖啡莊園</td>\n","      <td>0.10</td>\n","      <td>50</td>\n","      <td>Washed / Wet</td>\n","      <td>LIN REN FU 林人富</td>\n","      <td>baihe dist., tainan city 臺南市白河區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>700.00</td>\n","      <td>500.00</td>\n","      <td>600.00</td>\n","      <td>79.75</td>\n","    </tr>\n","    <tr>\n","      <th>1182</th>\n","      <td>1182</td>\n","      <td>7.25</td>\n","      <td>6.83</td>\n","      <td>7.08</td>\n","      <td>20 kg</td>\n","      <td>7.08</td>\n","      <td>7.42</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>6.75</td>\n","      <td>November 7th, 2015</td>\n","      <td>BaiShenCun Coffee Farm百勝村咖啡莊園</td>\n","      <td>6.83</td>\n","      <td>November 7th, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>baishengcun coffee 百勝村咖啡莊園</td>\n","      <td>0.11</td>\n","      <td>50</td>\n","      <td>Washed / Wet</td>\n","      <td>WU SHU YI 巫叔憶</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>850.00</td>\n","      <td>850.00</td>\n","      <td>850.00</td>\n","      <td>79.25</td>\n","    </tr>\n","    <tr>\n","      <th>1217</th>\n","      <td>1217</td>\n","      <td>7.25</td>\n","      <td>7.17</td>\n","      <td>6.83</td>\n","      <td>20 kg</td>\n","      <td>6.92</td>\n","      <td>7.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>6.67</td>\n","      <td>July 22nd, 2015</td>\n","      <td>Kan Tou Mountain Coffee 崁頭山咖啡館</td>\n","      <td>6.75</td>\n","      <td>July 22nd, 2014</td>\n","      <td>2013</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>kan tou mountain coffee 崁頭山咖啡館</td>\n","      <td>0.10</td>\n","      <td>50</td>\n","      <td>Washed / Wet</td>\n","      <td>GUO JIUN HUNG 郭俊宏 &amp; TSENG RU FENG 曾如楓</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>78.58</td>\n","    </tr>\n","    <tr>\n","      <th>1249</th>\n","      <td>1249</td>\n","      <td>7.17</td>\n","      <td>6.67</td>\n","      <td>7.00</td>\n","      <td>10 kg</td>\n","      <td>6.83</td>\n","      <td>6.83</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>9.33</td>\n","      <td>Green</td>\n","      <td>unex guatemala, s.a.</td>\n","      <td>Taiwan</td>\n","      <td>6.67</td>\n","      <td>February 7th, 2014</td>\n","      <td>Dongshan Gaoyuan village chief manor coffee Ta...</td>\n","      <td>6.83</td>\n","      <td>May 29th, 2013</td>\n","      <td>2012</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>beneficio ixchel</td>\n","      <td>0.11</td>\n","      <td>100</td>\n","      <td>Washed / Wet</td>\n","      <td>LUIS RODRIGUEZ</td>\n","      <td>oriente</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Bourbon</td>\n","      <td>1310.64</td>\n","      <td>1310.64</td>\n","      <td>1310.64</td>\n","      <td>77.67</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Unnamed: 0  Acidity  ...  altitude_mean_meters  quality_score\n","29            29     8.25  ...               1200.00          86.58\n","43            43     8.08  ...               1000.00          86.08\n","108          108     7.58  ...                800.00          84.92\n","115          115     7.83  ...                350.00          84.83\n","175          175     8.00  ...               1200.00          84.42\n","191          191     7.67  ...               1000.00          84.25\n","233          233     7.67  ...                968.00          84.08\n","262          262     7.75  ...               1200.00          83.92\n","269          269     7.92  ...                950.00          83.92\n","280          280     7.75  ...                525.00          83.83\n","298          298     7.58  ...                750.00          83.75\n","319          319     7.92  ...               1200.00          83.67\n","425          425     7.50  ...               1000.00          83.25\n","426          426     7.58  ...                800.00          83.25\n","483          483     7.83  ...                750.00          83.08\n","508          508     7.58  ...               1200.00          83.00\n","536          536     7.67  ...                350.00          82.92\n","538          538     7.33  ...                775.00          82.92\n","585          585     7.67  ...                650.00          82.75\n","617          617     7.42  ...               1200.00          82.67\n","634          634     7.42  ...               1050.00          82.58\n","770          770     7.17  ...                800.00          82.17\n","801          801     7.42  ...                600.00          82.00\n","806          806     7.42  ...                650.00          82.00\n","844          844     7.25  ...                700.00          81.83\n","897          897     7.67  ...                800.00          81.58\n","914          914     7.08  ...                180.00          81.50\n","919          919     7.33  ...                900.00          81.50\n","938          938     7.17  ...                110.00          81.42\n","962          962     7.83  ...                680.00          81.25\n","1004        1004     7.25  ...                758.00          81.00\n","1021        1021     7.08  ...                550.00          80.92\n","1080        1080     7.17  ...                600.00          80.42\n","1115        1115     7.17  ...                850.00          80.08\n","1146        1146     7.00  ...                600.00          79.75\n","1182        1182     7.25  ...                850.00          79.25\n","1217        1217     7.25  ...                800.00          78.58\n","1249        1249     7.17  ...               1310.64          77.67\n","\n","[38 rows x 35 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"Pdy7AhiboJGY","colab_type":"text"},"source":["Say that out of the Taiwanese coffees, we only want to look at those which are the Bourbon variety. We can also chain those indexing operations like so:"]},{"cell_type":"code","metadata":{"id":"fK2anT_loJGY","colab_type":"code","outputId":"309eeee3-8415-462c-81b9-34129be18687","executionInfo":{"status":"ok","timestamp":1574354444953,"user_tz":300,"elapsed":7797,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":468}},"source":["df_clean[df_clean['Country of Origin'] == 'Taiwan'][df_clean['Variety'] == 'Bourbon']"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Acidity</th>\n","      <th>Aftertaste</th>\n","      <th>Aroma</th>\n","      <th>Bag Weight</th>\n","      <th>Balance</th>\n","      <th>Body</th>\n","      <th>Category.One.Defects</th>\n","      <th>Category.Two.Defects</th>\n","      <th>Clean Cup</th>\n","      <th>Color</th>\n","      <th>Company</th>\n","      <th>Country of Origin</th>\n","      <th>Cupper Points</th>\n","      <th>Expiration</th>\n","      <th>Farm Name</th>\n","      <th>Flavor</th>\n","      <th>Grading Date</th>\n","      <th>Harvest Year</th>\n","      <th>ICO Number</th>\n","      <th>In-Country Partner</th>\n","      <th>Mill</th>\n","      <th>Moisture</th>\n","      <th>Number of Bags</th>\n","      <th>Processing Method</th>\n","      <th>Producer</th>\n","      <th>Region</th>\n","      <th>Species</th>\n","      <th>Sweetness</th>\n","      <th>Uniformity</th>\n","      <th>Variety</th>\n","      <th>altitude_high_meters</th>\n","      <th>altitude_low_meters</th>\n","      <th>altitude_mean_meters</th>\n","      <th>quality_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>43</th>\n","      <td>43</td>\n","      <td>8.08</td>\n","      <td>7.75</td>\n","      <td>8.08</td>\n","      <td>15 kg</td>\n","      <td>7.83</td>\n","      <td>7.75</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>8.42</td>\n","      <td>June 9th, 2016</td>\n","      <td>Sunshine Valley Estate 向陽高山咖啡</td>\n","      <td>8.17</td>\n","      <td>June 10th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>sunshine valley estate 向陽高山咖啡</td>\n","      <td>0.12</td>\n","      <td>10</td>\n","      <td>Semi-washed / Semi-pulped</td>\n","      <td>LIN YEN CHIEN 林言謙</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.0</td>\n","      <td>10.0</td>\n","      <td>Bourbon</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>86.08</td>\n","    </tr>\n","    <tr>\n","      <th>425</th>\n","      <td>425</td>\n","      <td>7.50</td>\n","      <td>7.50</td>\n","      <td>7.67</td>\n","      <td>15 kg</td>\n","      <td>7.83</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.58</td>\n","      <td>June 17th, 2016</td>\n","      <td>Sunshine Valley Estate 向陽高山咖啡</td>\n","      <td>7.50</td>\n","      <td>June 18th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>sunshine valley estate 向陽高山咖啡</td>\n","      <td>0.10</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>LIN YEN CHIEN 林言謙</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.0</td>\n","      <td>10.0</td>\n","      <td>Bourbon</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>83.25</td>\n","    </tr>\n","    <tr>\n","      <th>1249</th>\n","      <td>1249</td>\n","      <td>7.17</td>\n","      <td>6.67</td>\n","      <td>7.00</td>\n","      <td>10 kg</td>\n","      <td>6.83</td>\n","      <td>6.83</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>9.33</td>\n","      <td>Green</td>\n","      <td>unex guatemala, s.a.</td>\n","      <td>Taiwan</td>\n","      <td>6.67</td>\n","      <td>February 7th, 2014</td>\n","      <td>Dongshan Gaoyuan village chief manor coffee Ta...</td>\n","      <td>6.83</td>\n","      <td>May 29th, 2013</td>\n","      <td>2012</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>beneficio ixchel</td>\n","      <td>0.11</td>\n","      <td>100</td>\n","      <td>Washed / Wet</td>\n","      <td>LUIS RODRIGUEZ</td>\n","      <td>oriente</td>\n","      <td>Arabica</td>\n","      <td>10.0</td>\n","      <td>10.0</td>\n","      <td>Bourbon</td>\n","      <td>1310.64</td>\n","      <td>1310.64</td>\n","      <td>1310.64</td>\n","      <td>77.67</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Unnamed: 0  Acidity  ...  altitude_mean_meters  quality_score\n","43            43     8.08  ...               1000.00          86.08\n","425          425     7.50  ...               1000.00          83.25\n","1249        1249     7.17  ...               1310.64          77.67\n","\n","[3 rows x 35 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"JghslLyIoJGZ","colab_type":"text"},"source":["### Scikit-learn Basics\n","\n","Scikit-learn is a great library to use for doing machine learning in Python. Data preparation, exploratory data analysis (EDA), classification, regression, clustering; it has it all. \n","\n","Scikit-learn usually expects data to be in the form of a 2D matrix with dimensions *n_samples x n_features* with an additional column for the target. To get acquainted with scikit-learn, we are going to use the [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris), one of the most famous datasets in pattern recognition. \n","\n","Each entry in the dataset represents an iris plant, and is categorized as: \n","\n","* Setosa (class 0)\n","* Versicolor (class 1)\n","* Virginica (class 2)\n","\n","These represent the target classes to predict. Each entry also includes a set of features, namely:\n","\n","* Sepal width (cm)\n","* Sepal length (cm)\n","* Petal length (cm)\n","* Petal width (cm)\n","\n","In the context of machine learning classification, the remainder of the lab is going to investigate the following question:  \n","*Can we design a model that, based on the iris sample features, can accurately predict the iris sample class? *\n","\n","Scikit-learn has a copy of the iris dataset readily importable for us. Let's grab it now and conduct some EDA."]},{"cell_type":"code","metadata":{"id":"flfiIhwgoJGa","colab_type":"code","colab":{}},"source":["from sklearn.datasets import load_iris\n","iris_data = load_iris()\n","feature_data = iris_data.data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k4NUSHqyoJGb","colab_type":"text"},"source":["**YOUR TURN:** \"feature_data\" now contains the feature data for all of the iris samples. \n","* What is the shape of this feature data? ________________\n","--> Solution: (150, 4)\n","* The data type? _Solution:float64_______________\n","* How many samples are there? ___Solution:_600____________\n","* How many features are there? _Solution:__4_ features____________"]},{"cell_type":"code","metadata":{"id":"Z1IHiamcoJGb","colab_type":"code","outputId":"5726a6e1-bd36-4738-b79e-5381075954a9","executionInfo":{"status":"ok","timestamp":1574354445208,"user_tz":300,"elapsed":8033,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## Enter your code here\n","feature_data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150, 4)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"lZey1wc921P9","colab_type":"code","outputId":"09a8e68a-3a26-46b9-9be4-e08d94da9de8","executionInfo":{"status":"ok","timestamp":1574354445208,"user_tz":300,"elapsed":8015,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["##Data Type: Float64\n","feature_data.dtype"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dtype('float64')"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"aR40kheD3DPA","colab_type":"code","outputId":"1f34e221-4e00-4f03-cfbe-969335b9194a","executionInfo":{"status":"ok","timestamp":1574354445209,"user_tz":300,"elapsed":7998,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## number of samples: \n","feature_data.size"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["600"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"vmcjjD593J0Z","colab_type":"code","outputId":"74b987b1-faaf-4387-8e1b-d6feda145362","executionInfo":{"status":"ok","timestamp":1574354445209,"user_tz":300,"elapsed":7980,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## numbe of features: 4 (number of columns)\n","len(iris_data.feature_names)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"WQhxUGJFoJGc","colab_type":"text"},"source":["Next, we will save the target classification data in a similar fashion."]},{"cell_type":"code","metadata":{"id":"nYUsnObIoJGc","colab_type":"code","outputId":"4cd0b06d-a0dc-4cd1-ec51-41b79a44db5d","executionInfo":{"status":"ok","timestamp":1574354445492,"user_tz":300,"elapsed":8245,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["target_data = iris_data.target\n","target_names = iris_data.target_names\n","target_names.dtype"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dtype('<U10')"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"bnqM5ucroJGd","colab_type":"text"},"source":["**YOUR TURN:**\n","* What values are in \"target_data\"? _Solution:__0,1,2_________\n","* What is the data type? _Solution:___int64____________\n","* What values are in \"target_names\"? _['setosa', 'versicolor', 'virginica']\n","* What is the data type? _______<U10________\n","* How many samples are of type \"setosa\"? ______50__________"]},{"cell_type":"code","metadata":{"id":"hX2RMfsG5EXj","colab_type":"code","outputId":"738c1a49-e991-4583-89e5-8bf8b57631fa","executionInfo":{"status":"ok","timestamp":1574354445492,"user_tz":300,"elapsed":8228,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["#0,1,2 in target_data\n","target_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"fgc-8ATo5QcE","colab_type":"code","outputId":"c3c39552-a7ba-47e7-dc57-be8d83c2e72d","executionInfo":{"status":"ok","timestamp":1574354445493,"user_tz":300,"elapsed":8211,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# data type\n","target_data.dtype"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dtype('int64')"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"2rbcPi3U5ZRQ","colab_type":"code","outputId":"03ef26ab-ce9a-49b1-8743-0a8fd460ed61","executionInfo":{"status":"ok","timestamp":1574354445493,"user_tz":300,"elapsed":8194,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#What values are in \"target_names\"? ____\n","target_names"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"W_J6SwkD5khw","colab_type":"code","outputId":"6eb82607-62d1-40a4-c067-839361308e21","executionInfo":{"status":"ok","timestamp":1574354445494,"user_tz":300,"elapsed":8177,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#What is the data type? ____\n","target_names.dtype"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dtype('<U10')"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"BLB_6ZaJ5uAa","colab_type":"code","outputId":"7b10f869-3a04-4175-82c4-d54c5c8ebdd0","executionInfo":{"status":"ok","timestamp":1574354445494,"user_tz":300,"elapsed":8159,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#How many samples are of type \"setosa\"? ____\n","setosa = feature_data[target_data==0]\n","len(setosa)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"WFHlF8kEoJGe","colab_type":"code","colab":{}},"source":["## Enter your code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9VIjLD8RoJGf","colab_type":"text"},"source":["We can also do some more visual EDA by plotting the samples according to a subset of the features and coloring the data points to coincide with the sample classification. We will use [matplotlib](https://matplotlib.org/), a powerful plotting library within Python, to accomplish this.\n","\n","For example, lets plot sepal width vs. sepal length.\n"]},{"cell_type":"code","metadata":{"id":"60y6Yy7zoJGg","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yxr-oTnaoJGh","colab_type":"code","outputId":"fd9223e7-30ec-45b9-d67e-1bb73bd5f2ff","executionInfo":{"status":"ok","timestamp":1574354445659,"user_tz":300,"elapsed":8303,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["setosa = feature_data[target_data==0]\n","versicolor = feature_data[target_data==1]\n","virginica = feature_data[target_data==2]\n","\n","plt.scatter(setosa[:,0], setosa[:,1], label=\"setosa\")\n","plt.scatter(versicolor[:,0], versicolor[:,1], label=\"versicolor\")\n","plt.scatter(virginica[:,0], virginica[:,1], label=\"virginica\")\n","\n","plt.legend()\n","plt.xlabel(\"sepal length (cm)\")\n","plt.ylabel(\"sepal width (cm)\")\n","plt.title(\"Visual EDA\");"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"CqiWXVGToJGi","colab_type":"text"},"source":["In the above step, we used boolean indexing to filter the feature data based on the target data class. This allowed us to create a scatter plot for each of the iris classes and distinguish them by color.\n","\n","*Observations*: We can see that the \"setosa\" class typically consists of medium-to-high sepal width with low-to-medium sepal length, while the other two classes have lower width and higher length. The \"virginica\" class appears to have the largest combination of the two. \n","\n","**YOUR TURN:** \n","* Which of the iris classes is seperable based on sepal characteristics? ________________\n","-->**Solution: the Setosa is seperable**\n","* Which of the iris classes is not? ________________\n","--> **Solution: The versicolor and virginica cannot be seperated from the graph**\n","* Can we (easily) visualize each of the samples w.r.t. all features on the same plot? Why/why not? ________________\n","--> Solutions **NO, we need more features to seperate them, such as including the sepal length and speal width**"]},{"cell_type":"markdown","metadata":{"id":"6yar5YTAoJGj","colab_type":"text"},"source":["### Creating a Nearest Neighbors Classifier\n","\n","Now that we've explored the data a little bit, we're going to use scikit-learn to create a nearest neighbors classifier for the data. Effectively we'll be developing a model whose job it is to build a relationship over input feature data (sepal and petal characteristics) that predicts the iris sample class (e.g. \"setosa\"). This is an example of a *supervised learning* task; we have all the features and all the target classes.\n","\n","Model creation in scikit-learn follows a **data prep -> fit -> predict** process. The \"fit\" function is where the actual model is trained and parameter values are selected, while the \"predict\" function actually takes the trained model and applies it to the new samples.\n","\n","First, we load the nearest neighbor library from scikit-learn:"]},{"cell_type":"code","metadata":{"id":"_yFpq-h9oJGj","colab_type":"code","colab":{}},"source":["from sklearn import neighbors"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CPzTtk8roJGk","colab_type":"text"},"source":["Now, we're going to save our feature data into an array called 'X' and our target data into an array called 'y'. We don't *need* to do this, but it is traditional to think of the problem using this notation."]},{"cell_type":"code","metadata":{"id":"CZX6WgMjoJGk","colab_type":"code","colab":{}},"source":["X = feature_data\n","y = target_data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sags3EJ4oJGm","colab_type":"text"},"source":["Next, we create our nearest neighbor classifier object:"]},{"cell_type":"code","metadata":{"id":"TDby6Z-6oJGm","colab_type":"code","colab":{}},"source":["knn = neighbors.KNeighborsClassifier(n_neighbors=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ZaVns1ooJGo","colab_type":"text"},"source":["And then we *fit* it to the data (i.e., train the classifier)."]},{"cell_type":"code","metadata":{"id":"F2uDIsP9oJGq","colab_type":"code","outputId":"9a2eace2-8ff7-4500-c13d-398a5234b6e6","executionInfo":{"status":"ok","timestamp":1574354446163,"user_tz":300,"elapsed":8785,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["knn.fit(X,y)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n","                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n","                     weights='uniform')"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"m9qLzshxoJGr","colab_type":"text"},"source":["Now we have a model! If you're new to this, you've officially built your first machine learning model. If you use \"knn.predict(*[[feature array here]]*)\", you can use your trained model to predict the class of a new iris sample. \n","\n","**YOUR TURN:**\n","* What is the predicted class of a new iris sample with feature vector [3,4,5,2]? What is its name? ________________\n","--> **Solutions: The data class is 2 and name is virginica.**\n","\n","* Do you think this model is overfit or underfit to the iris dataset? Why? ________________\n","--> **Solutions: The model is overfit because it tries to fit every single point in the data set.**\n","* How many neighbors does our model consider when classifying a new sample? ________________\n","--> **Solutions: Since K =1, only 1 nearest neighbor is chosen when classifying a new sample.**"]},{"cell_type":"code","metadata":{"id":"ThmDOzVFoJGr","colab_type":"code","outputId":"c6b2c81f-032c-427b-b912-a9e8bd13350f","executionInfo":{"status":"ok","timestamp":1574354446163,"user_tz":300,"elapsed":8767,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# priection:\n","sample=np.array([3,4,5,2])\n","sample2=sample.reshape (1,-1)\n","prediction=knn.predict(sample2)\n","prediction"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2])"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"grjsglM5oJGs","colab_type":"text"},"source":["As you may have noted in the previous cell, we've trained this classifier on our *entire dataset*. This typically isn't done in practice and results in overfitting to the data. Here's a bit of a tricky question:\n","\n","**YOUR TURN:**\n","* If we use our classifier to predict the classes of the iris samples that were used to train the model itself, what will our overall accuracy be? _____100%___________\n","\n","We can validate our hypothesis fairly easily using either: i) the NumPy technique for calculating accuracy we used earlier in the lab, or ii) scikit-learn's in-house \"accuracy_score()\" function.\n","\n","Let's use our technique first:"]},{"cell_type":"code","metadata":{"id":"czS77Os8oJGt","colab_type":"code","outputId":"58dbdcb7-7b78-474a-cb90-494d7f4bb791","executionInfo":{"status":"ok","timestamp":1574354446163,"user_tz":300,"elapsed":8750,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["accuracy = np.sum(target_data == knn.predict(feature_data)) / target_data.size\n","print (\"Accuracy: \", accuracy * 100, \"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy:  100.0 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VlRFSBWIoJGu","colab_type":"text"},"source":["and then using scikit-learn's customized function:"]},{"cell_type":"code","metadata":{"id":"ae7QXH_EoJGu","colab_type":"code","outputId":"29350dbd-e8a7-4019-ac2b-80074415bfe2","executionInfo":{"status":"ok","timestamp":1574354446164,"user_tz":300,"elapsed":8733,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.metrics import accuracy_score\n","accuracy = accuracy_score(target_data, knn.predict(feature_data))\n","print (\"Accuracy: \", accuracy * 100, \"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy:  100.0 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ojZn8Ly8oJGw","colab_type":"text"},"source":["We see that our classifier has achieved 100% accuracy (and both calculation methods agree)!\n","\n","**DISCUSSION:** \n","* Why do you think the model was able to achieve such a \"great\" result? \n","-->**Solutions: The created model tries to fit every data in the dataset and, thus, trained by all the data samples, which is why the accuracy is perfect for the current sample dataset.**\n","* What does this really tell us? \n","--> **Solutions: It bascially tells us that the model works perfectly (100% accuracy) on the current dataset, but is not able to tell if the model is good for the new dataset.**\n","* Do you expect the model to perform this well on new data?\n","--> **Solutions: First, the model was trained on every single point in the current dataset so that this model works well for all the trained data, but may not work well for different or new data points. Second, Since the K was chosen to be 1, the model seems to be baised and not very good for pretecting the new data.**"]},{"cell_type":"markdown","metadata":{"id":"G5K78afZoJG4","colab_type":"text"},"source":["### Exercises (to be completed on your own)\n","\n","Let's take the tools we have learned in this lab and put them into practice on a new dataset.\n","\n","We're going to work with a dataset focused on diabetes. It contains a variety of health metrics for a number of patients, and then in a second object it shows whether or not that patient had diabetes. Download it using the cell below:"]},{"cell_type":"code","metadata":{"id":"SkFlVlNGoJG4","colab_type":"code","colab":{}},"source":["from sklearn.datasets import fetch_openml\n","\n","diabetes_data = fetch_openml(\n","    name='diabetes',\n","    cache=False\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BLwmertOoJG5","colab_type":"text"},"source":["First off, take a look at the `data`, `target` and `feature_names` entires in the `diabetes_data` dictionary. They contain the information we'll be working with here. Then, create a Pandas DataFrame called `diabetes_df` containing the data and the targets, with the feature names as column headings. If you need help, refer [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) for more detail on how to achieve this.\n","\n","* What was the average age of participants? [1] ____\n","--> **Solution: average age is 33.24 (see the code below)**\n","* How many participants tested positive? How many tested negative? [1] ____\n","--> **Solutions: Positive: 268 and Negative: 500**"]},{"cell_type":"code","metadata":{"id":"oOgVWHG-oJG5","colab_type":"code","colab":{}},"source":["### YOUR CODE HERE\n","feature_data=diabetes_data.data\n","target_data=diabetes_data.target\n","feature_names=diabetes_data.feature_names"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTit9F-Iqh28","colab_type":"code","outputId":"374bcb3a-2889-449b-d9c6-0b299fe14e7f","executionInfo":{"status":"ok","timestamp":1574354449271,"user_tz":300,"elapsed":11819,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# creating a data frame for diabetes_df\n","diabetes_1= pd.DataFrame(feature_data,columns=['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age'])\n","diabetes_2=pd.DataFrame(target_data,columns=['target'])\n","diabetes_df =pd.concat([diabetes_1,diabetes_2],axis=1)\n","diabetes_df.head() # display the first 10 rows to check the pandas data frame"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preg</th>\n","      <th>plas</th>\n","      <th>pres</th>\n","      <th>skin</th>\n","      <th>insu</th>\n","      <th>mass</th>\n","      <th>pedi</th>\n","      <th>age</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.0</td>\n","      <td>148.0</td>\n","      <td>72.0</td>\n","      <td>35.0</td>\n","      <td>0.0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50.0</td>\n","      <td>tested_positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>85.0</td>\n","      <td>66.0</td>\n","      <td>29.0</td>\n","      <td>0.0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31.0</td>\n","      <td>tested_negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8.0</td>\n","      <td>183.0</td>\n","      <td>64.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32.0</td>\n","      <td>tested_positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>89.0</td>\n","      <td>66.0</td>\n","      <td>23.0</td>\n","      <td>94.0</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21.0</td>\n","      <td>tested_negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>137.0</td>\n","      <td>40.0</td>\n","      <td>35.0</td>\n","      <td>168.0</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33.0</td>\n","      <td>tested_positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   preg   plas  pres  skin   insu  mass   pedi   age           target\n","0   6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0  tested_positive\n","1   1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0  tested_negative\n","2   8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0  tested_positive\n","3   1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0  tested_negative\n","4   0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0  tested_positive"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"qfWGzh4FsnO6","colab_type":"code","outputId":"450b5830-ddbb-4a8a-d69a-9d2cf2c3c305","executionInfo":{"status":"ok","timestamp":1574354449272,"user_tz":300,"elapsed":11803,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# What was the average age of participants? [1]:  the mean age is 33.24\n","diabetes_df ['age'].mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["33.240885416666664"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"pdHZOQ_Ps-_k","colab_type":"code","outputId":"c69fb683-1fde-402b-b273-859b267ba960","executionInfo":{"status":"ok","timestamp":1574354449272,"user_tz":300,"elapsed":11785,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#How many participants tested positive? How many tested negative? 268 tested positice and 500 tested negative\n","df_positive= diabetes_df [diabetes_df['target']=='tested_positive'] # tested postive\n","len(df_positive)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["268"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"rdArQnPlup69","colab_type":"code","outputId":"54f06b69-4587-40d2-d343-2342712b72db","executionInfo":{"status":"ok","timestamp":1574354449273,"user_tz":300,"elapsed":11769,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df_negative= diabetes_df [diabetes_df['target']=='tested_negative'] # tested negative\n","len(df_negative)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["500"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"markdown","metadata":{"id":"i7qnyte6oJG6","colab_type":"text"},"source":["The targets are currently a string representing whether or not the patient has diabetes. However, it's more useful for us if this column contains a 1 or a 0 depending on whether the patient has diabetes. Use the [Label Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) class from Scikit-Learn to convert the labels into integers."]},{"cell_type":"code","metadata":{"id":"rqDw_D2doJG7","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder\n","### YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"giuNLIzu9JR9","colab_type":"code","outputId":"b4fb0ed2-9139-4efb-c77d-1abe65c2c1bc","executionInfo":{"status":"ok","timestamp":1574354449425,"user_tz":300,"elapsed":11900,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn import preprocessing\n","encoder = preprocessing.LabelEncoder()\n","labels=['tested_negative','tested_positive']\n","encoder.fit(labels)\n","list(encoder.classes_)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['tested_negative', 'tested_positive']"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"PW8A8vbM9aOp","colab_type":"code","outputId":"54a46b83-7a52-43c1-cd65-52b2e9a42c5e","executionInfo":{"status":"ok","timestamp":1574354449426,"user_tz":300,"elapsed":11882,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder.transform(labels)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"TH6bt69N1qa3","colab_type":"code","colab":{}},"source":["# create a encoded tate data\n","target_data2 = encoder.transform(target_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TmhtyVRav7or","colab_type":"code","colab":{}},"source":["# add the new taget_data2 to the data frame\n","diabetes_3 = pd.DataFrame(target_data2, columns = ['target_label'])\n","diabetes_df = pd.concat([diabetes_1,diabetes_2,diabetes_3],axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kANitNmToJG9","colab_type":"text"},"source":["Now we are going to create a classifier to predict whether a patient has diabetes based on their vitals. \n","\n","Using `cross_val_score`, report mean cross validation accuracy on a KNN classifier with K=3 and 10 folds. Remember that the `target` column holds our labels.\n","\n","* What accuracy did the model achieve?[1] __\n","**Solutions: training accuracy: 0.68 and test set accuracy: 69.264%**\n","* Find a value for K that performs better than this. What value for K did you use? What was the performance? [2] __\n","\n","**Solutions: Based on several iteration, k=15 is seleted, as it could give me the best performance. For example, the training accuracy = 0.74 and Test set accuracy: 75.75% when k = 15**"]},{"cell_type":"code","metadata":{"id":"oIDm_Cn5oJG9","colab_type":"code","outputId":"3a3eeaf8-a06f-4160-f86e-51d26db871ff","executionInfo":{"status":"ok","timestamp":1574354449427,"user_tz":300,"elapsed":11866,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["### When k = 3\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(feature_data,target_data2,test_size=0.3,random_state=0)\n","knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n","\n","from sklearn.model_selection import cross_val_score\n","scores=cross_val_score(knn,X_train,y_train,cv=10)\n","print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores.mean(),scores.std()*2))\n","\n","knn.fit(X_train,y_train)\n","accuracy=accuracy_score(y_test,knn.predict(X_test))\n","print(\"Test set accuracy: \",accuracy*100,\"%\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 0.68(+/- 0.09)\n","Test set accuracy:  69.26406926406926 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9d2sXM-26HHx","colab_type":"code","outputId":"171cf698-3f51-4a44-dc27-ff5b6b3bea6a","executionInfo":{"status":"ok","timestamp":1574354509808,"user_tz":300,"elapsed":692,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Iteraation: When k = 12\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(feature_data,target_data2,test_size=0.3,random_state=0)\n","knn = neighbors.KNeighborsClassifier(n_neighbors=12)\n","from sklearn.model_selection import cross_val_score\n","scores=cross_val_score(knn,X_train,y_train,cv=10)\n","#print(scores)\n","print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores.mean(),scores.std()*2))\n","\n","knn.fit(X_train,y_train)\n","accuracy = accuracy_score(y_test,knn.predict(X_test))\n","print(\"Test set accuracy: \",accuracy*100,\"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 0.76(+/- 0.10)\n","Test set accuracy:  75.75757575757575 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z4Bnl8ZR5HY4","colab_type":"code","outputId":"9ca99794-d315-45b0-b1e6-6cb023c921d6","executionInfo":{"status":"ok","timestamp":1574354449718,"user_tz":300,"elapsed":12131,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Iteration: When k = 15\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(feature_data,target_data2,test_size=0.3,random_state=0)\n","knn = neighbors.KNeighborsClassifier(n_neighbors=15)\n","\n","from sklearn.model_selection import cross_val_score\n","scores=cross_val_score(knn,X_train,y_train,cv=10)\n","print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores.mean(),scores.std()*2))\n","\n","knn.fit(X_train,y_train)\n","accuracy=accuracy_score(y_test,knn.predict(X_test))\n","print(\"Test set accuracy: \",accuracy*100,\"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 0.74(+/- 0.07)\n","Test set accuracy:  75.75757575757575 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mYPM-3wHoJG-","colab_type":"text"},"source":["Take a look at the `skin` feature.\n","\n","* According to the dataset description in `diabetes_data['DESCR']`, what does this feature represent? [1] ____\n","--> **Solutions: it represents the Triceps skin fold thickness (mm)**\n","* Are there any unusual entries in this column? If so, why? [2] ____\n","-->**solutions: Yes, there are missing values. This because that it is very difficult to collect all the values in the first place.**\n","\n","Use the `SimpleImputer` class from scikit-learn to impute missing values for the `skin` and `insu` columns. Overwrite the existing `skin` and `insu` columns with these new values."]},{"cell_type":"code","metadata":{"id":"90gCGSVHoJG-","colab_type":"code","colab":{}},"source":["# Impute the mean values to the data set\n","diabetes_imp = diabetes_1 # copy the vlues from old feature values\n","from sklearn.impute import SimpleImputer\n","imp = SimpleImputer(missing_values=0,strategy='mean',verbose=1)\n","\n","# impute the means for skin column\n","imp.fit(diabetes_imp['skin'].values.reshape((-1,1)))\n","diabetes_imp['skin']=imp.transform(diabetes_imp['skin'].values.reshape((-1,1)))\n","\n","# impute the means for insu column:\n","imp.fit(diabetes_imp['insu'].values.reshape((-1,1)))\n","diabetes_imp['insu']=imp.transform(diabetes_imp['insu'].values.reshape((-1,1)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ksJ4B6LOs0la","colab_type":"code","outputId":"1195a1ce-2140-43a3-dc73-a7b368c05bf5","executionInfo":{"status":"ok","timestamp":1574354449719,"user_tz":300,"elapsed":12117,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# Adding the imputed values to the date frame\n","diabetes_2 = pd.DataFrame(target_data,columns=['target'])\n","diabetes_df_imp = pd.concat([diabetes_imp,diabetes_2,diabetes_3],axis=1)\n","diabetes_df_imp.head() # display the first 10 rows to make sure the means are successfully imputed"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preg</th>\n","      <th>plas</th>\n","      <th>pres</th>\n","      <th>skin</th>\n","      <th>insu</th>\n","      <th>mass</th>\n","      <th>pedi</th>\n","      <th>age</th>\n","      <th>target</th>\n","      <th>target_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.0</td>\n","      <td>148.0</td>\n","      <td>72.0</td>\n","      <td>35.00000</td>\n","      <td>155.548223</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50.0</td>\n","      <td>tested_positive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>85.0</td>\n","      <td>66.0</td>\n","      <td>29.00000</td>\n","      <td>155.548223</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8.0</td>\n","      <td>183.0</td>\n","      <td>64.0</td>\n","      <td>29.15342</td>\n","      <td>155.548223</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32.0</td>\n","      <td>tested_positive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>89.0</td>\n","      <td>66.0</td>\n","      <td>23.00000</td>\n","      <td>94.000000</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>137.0</td>\n","      <td>40.0</td>\n","      <td>35.00000</td>\n","      <td>168.000000</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33.0</td>\n","      <td>tested_positive</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   preg   plas  pres      skin  ...   pedi   age           target  target_label\n","0   6.0  148.0  72.0  35.00000  ...  0.627  50.0  tested_positive             1\n","1   1.0   85.0  66.0  29.00000  ...  0.351  31.0  tested_negative             0\n","2   8.0  183.0  64.0  29.15342  ...  0.672  32.0  tested_positive             1\n","3   1.0   89.0  66.0  23.00000  ...  0.167  21.0  tested_negative             0\n","4   0.0  137.0  40.0  35.00000  ...  2.288  33.0  tested_positive             1\n","\n","[5 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"markdown","metadata":{"id":"M0uktoPhoJG_","colab_type":"text"},"source":["Re-split the data and fit a new classifier.\n","\n","* Is performance better or worse with imputed values? Why might this be? [2] ____\n","\n","**-->Solutions: For training accuracy, both data sets could achieve the same score (0.74). However, for the test set accuracy, the data set with the imputed values could achieve an accuracy of 77.489% while the orginal data set (with zeros) has an accuracy of 75.75%. Thus, the model trained with imputed date values perfoms better and is more accurate. In addition, the new data set with imputed values has a smaller K value (k=8) whereas the orginial data set (no imputed values) has a k of 15. This means that the model trained with imputed values requires less samples to diagnose if a person has daibetes.**"]},{"cell_type":"code","metadata":{"id":"9impREmUoJHA","colab_type":"code","outputId":"f1277548-c8ed-4060-b452-56a8bc104838","executionInfo":{"status":"ok","timestamp":1574354449720,"user_tz":300,"elapsed":12105,"user":{"displayName":"Charlie wu","photoUrl":"","userId":"04524143671500281367"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["### YOUR CODE HERE\n","# re-split the date with K = 8\n","feature_data_imp = diabetes_imp.values\n","\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(feature_data_imp,target_data2,test_size=0.3,random_state=0)\n","knn = neighbors.KNeighborsClassifier(n_neighbors=8)\n","\n","from sklearn.model_selection import cross_val_score\n","scores = cross_val_score(knn,X_train,y_train,cv=10)\n","print(\"Accuracy: %0.2f(+/- %0.2f)\"%(scores.mean(),scores.std()*2))\n","\n","knn.fit(X_train,y_train)\n","accuracy=accuracy_score(y_test,knn.predict(X_test))\n","print(\"Test set accuracy: \",accuracy*100,\"%\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 0.74(+/- 0.11)\n","Test set accuracy:  77.48917748917748 %\n"],"name":"stdout"}]}]}